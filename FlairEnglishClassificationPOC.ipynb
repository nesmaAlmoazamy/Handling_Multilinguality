{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Flair Embedding and Glove over English dataset with 2 categories as a POC due to resources shortage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('../data/dataset.csv', sep='\\t', header=None).applymap(str)\n",
    "dataset.columns = [\"Language\",\"label\",\"text\"]\n",
    "languagesData=[]\n",
    "loc = 0\n",
    "languages = dataset[dataset.columns[0]].unique()\n",
    "for i in languages:\n",
    "    name = languages[loc]+\"Data\" \n",
    "    globals()[name] = pd.DataFrame( dataset[dataset.Language == i])\n",
    "    loc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(englishData)\n",
    "englishData = englishData[1:180]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language        label                                               text\n",
      "1  english  advertising  trump asks sec to mull half-year corporate fil...\n",
      "2  english  advertising  wall st. up on trade hopes, s&p equals longest...\n",
      "3  english  advertising  asian shares hit one-year low on turkey, china...\n",
      "4  english  advertising  asian stocks weaken as turkey worries weigh, d...\n",
      "5  english  advertising  most asian shares edge up after wall st. gains...\n"
     ]
    }
   ],
   "source": [
    "def lower_words(text):\n",
    "    text = text.str.lower()\n",
    "    return text\n",
    "\n",
    "englishData['text'] = lower_words(englishData['text'])\n",
    "input_str = englishData['text']\n",
    "print(englishData.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>trump asks sec to mull half-year corporate fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>wall st. up on trade hopes, s&amp;p equals longest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>asian shares hit one-year low on turkey, china...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>asian stocks weaken as turkey worries weigh, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>most asian shares edge up after wall st. gains...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language        label                                               text\n",
       "1  english  advertising  trump asks sec to mull half-year corporate fil...\n",
       "2  english  advertising  wall st. up on trade hopes, s&p equals longest...\n",
       "3  english  advertising  asian shares hit one-year low on turkey, china...\n",
       "4  english  advertising  asian stocks weaken as turkey worries weigh, d...\n",
       "5  english  advertising  most asian shares edge up after wall st. gains..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "def remove_url(text):\n",
    "    text = text.apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "    return text\n",
    "\n",
    "\n",
    "englishData['text'] = remove_url(englishData['text'])\n",
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>trump asks sec to mull half-year corporate fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>wall st. up on trade hopes, s&amp;p equals longest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>asian shares hit one-year low on turkey, china...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>asian stocks weaken as turkey worries weigh, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>most asian shares edge up after wall st. gains...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language        label                                               text\n",
       "1  english  advertising  trump asks sec to mull half-year corporate fil...\n",
       "2  english  advertising  wall st. up on trade hopes, s&p equals longest...\n",
       "3  english  advertising  asian shares hit one-year low on turkey, china...\n",
       "4  english  advertising  asian stocks weaken as turkey worries weigh, d...\n",
       "5  english  advertising  most asian shares edge up after wall st. gains..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_numbers(text):\n",
    "    text = text.str.replace('\\d+', '')\n",
    "    return text\n",
    "\n",
    "\n",
    "englishData['text'] = remove_numbers(englishData['text'])\n",
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>trump asks sec to mull halfyear corporate fili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>wall st up on trade hopes sp equals longest bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>asian shares hit oneyear low on turkey china w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>asian stocks weaken as turkey worries weigh do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>most asian shares edge up after wall st gains ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language        label                                               text\n",
       "1  english  advertising  trump asks sec to mull halfyear corporate fili...\n",
       "2  english  advertising  wall st up on trade hopes sp equals longest bu...\n",
       "3  english  advertising  asian shares hit oneyear low on turkey china w...\n",
       "4  english  advertising  asian stocks weaken as turkey worries weigh do...\n",
       "5  english  advertising  most asian shares edge up after wall st gains ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuations(text):\n",
    "    text = text.str.replace('[^\\w\\s]','')\n",
    "    return text\n",
    "\n",
    "\n",
    "englishData['text'] = remove_punctuations(englishData['text'])\n",
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>trump asks sec to mull halfyear corporate fili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>wall st up on trade hopes sp equals longest bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>asian shares hit oneyear low on turkey china w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>asian stocks weaken as turkey worries weigh do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>most asian shares edge up after wall st gains ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language        label                                               text\n",
       "1  english  advertising  trump asks sec to mull halfyear corporate fili...\n",
       "2  english  advertising  wall st up on trade hopes sp equals longest bu...\n",
       "3  english  advertising  asian shares hit oneyear low on turkey china w...\n",
       "4  english  advertising  asian stocks weaken as turkey worries weigh do...\n",
       "5  english  advertising  most asian shares edge up after wall st gains ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def remove_blank_space(col):\n",
    "    col = col.str.strip()\n",
    "    col = col.replace('\\s+', ' ', regex=True)   \n",
    "    return col\n",
    "\n",
    "\n",
    "englishData['text'] = remove_blank_space(englishData.text)\n",
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>musk bid for tesla no formal offer no firm dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>wall st rallies on solid earnings uschina trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>iran says no opec member can take over its sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>online courses in data science that could help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>vws ceo was told about emissions software mont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language        label                                               text\n",
       "6   english  advertising  musk bid for tesla no formal offer no firm dea...\n",
       "7   english  advertising  wall st rallies on solid earnings uschina trad...\n",
       "8   english  advertising  iran says no opec member can take over its sha...\n",
       "9   english  advertising  online courses in data science that could help...\n",
       "10  english  advertising  vws ceo was told about emissions software mont..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "def remove_stop_words(text, stop):    \n",
    "    text.apply(lambda x: [item for item in x if item not in stop])\n",
    "    return text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "remove_stop_words(englishData['text'],stop)\n",
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>trump ask sec to mull halfyear corpor file vs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>wall st up on trade hope sp equal longest bull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>asian share hit oneyear low on turkey china wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>asian stock weaken as turkey worri weigh dolla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>most asian share edg up after wall st gain but...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language        label                                               text\n",
       "1  english  advertising  trump ask sec to mull halfyear corpor file vs ...\n",
       "2  english  advertising  wall st up on trade hope sp equal longest bull...\n",
       "3  english  advertising  asian share hit oneyear low on turkey china wo...\n",
       "4  english  advertising  asian stock weaken as turkey worri weigh dolla...\n",
       "5  english  advertising  most asian share edg up after wall st gain but..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.split()\n",
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "englishData['text'] = englishData['text'].apply(stem_sentences)\n",
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishData = englishData[[\"label\",\"text\"]]\n",
    "englishData['label'] = '__label__' + englishData['label'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "englishData.iloc[0:int(len(englishData)*0.8)].to_csv('train.csv', sep='\\t', index = False, header = False)\n",
    "englishData.iloc[int(len(englishData)*0.8):int(len(englishData)*0.9)].to_csv('test.csv', sep='\\t', index = False, header = False)\n",
    "englishData.iloc[int(len(englishData)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>__label__advertising</td>\n",
       "      <td>musk bid for tesla no formal offer no firm dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>__label__advertising</td>\n",
       "      <td>wall st ralli on solid earn uschina trade talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>__label__advertising</td>\n",
       "      <td>iran say no opec member can take over it share...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>__label__advertising</td>\n",
       "      <td>onlin cours in data scienc that could help you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>__label__advertising</td>\n",
       "      <td>vw ceo wa told about emiss softwar month befor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label                                               text\n",
       "6   __label__advertising  musk bid for tesla no formal offer no firm dea...\n",
       "7   __label__advertising  wall st ralli on solid earn uschina trade talk...\n",
       "8   __label__advertising  iran say no opec member can take over it share...\n",
       "9   __label__advertising  onlin cours in data scienc that could help you...\n",
       "10  __label__advertising  vw ceo wa told about emiss softwar month befor..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 1.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting deprecated>=1.2.4 (from flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/9f/7a/003fa432f1e45625626549726c2fbb7a29baa764e9d1fdb2323a5d779f8a/Deprecated-1.2.5-py2.py3-none-any.whl\n",
      "Collecting sqlitedict>=1.6.0 (from flair)\n",
      "Collecting hyperopt>=0.1.1 (from flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/63/12/704382c3081df3ae3f9d96fe6afb62efa2fa9749be20c301cd2797fb0b52/hyperopt-0.1.2-py3-none-any.whl\n",
      "Collecting tabulate (from flair)\n",
      "Requirement already satisfied: pytest>=3.6.4 in /home/kamel/anaconda3/lib/python3.7/site-packages (from flair) (4.3.1)\n",
      "Collecting pytorch-pretrained-bert>=0.6.1 (from flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20 in /home/kamel/anaconda3/lib/python3.7/site-packages (from flair) (1.24.1)\n",
      "Collecting torch>=1.0.0 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/23/a4b5c189dd624411ec84613b717594a00480282b949e3448d189c4aa4e47/torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 676.9MB 64kB/s eta 0:00:011  3% |█▏                              | 25.2MB 2.2MB/s eta 0:04:58    18% |██████                          | 127.0MB 1.8MB/s eta 0:05:06    19% |██████▎                         | 133.0MB 1.4MB/s eta 0:06:34    21% |██████▊                         | 142.3MB 1.8MB/s eta 0:05:01    22% |███████▎                        | 153.2MB 1.7MB/s eta 0:05:01    28% |█████████                       | 190.3MB 1.8MB/s eta 0:04:28    45% |██████████████▌                 | 306.9MB 1.8MB/s eta 0:03:27    46% |██████████████▉                 | 312.8MB 1.8MB/s eta 0:03:19    46% |███████████████                 | 315.7MB 6.8MB/s eta 0:00:53    54% |█████████████████▎              | 366.3MB 1.3MB/s eta 0:03:52    56% |██████████████████▎             | 385.8MB 219kB/s eta 0:22:04    58% |██████████████████▊             | 395.4MB 768kB/s eta 0:06:07    58% |██████████████████▊             | 396.6MB 251kB/s eta 0:18:34    61% |███████████████████▊            | 417.5MB 8.0MB/s eta 0:00:33    64% |████████████████████▊           | 438.3MB 1.8MB/s eta 0:02:13    66% |█████████████████████▏          | 448.0MB 701kB/s eta 0:05:27s eta 0:00:04    68% |█████████████████████▉          | 462.8MB 438kB/s eta 0:08:08    68% |██████████████████████          | 464.5MB 1.9MB/s eta 0:01:52��█▌         | 476.9MB 39.6MB/s eta 0:00:06    73% |███████████████████████▍        | 495.8MB 1.8MB/s eta 0:01:43    75% |████████████████████████        | 509.9MB 1.8MB/s eta 0:01:35    77% |████████████████████████▉       | 525.7MB 1.9MB/s eta 0:01:22    80% |█████████████████████████▊      | 543.5MB 1.8MB/s eta 0:01:13    83% |██████████████████████████▊     | 564.6MB 458kB/s eta 0:04:05    83% |██████████████████████████▊     | 565.5MB 1.7MB/s eta 0:01:04    89% |████████████████████████████▋   | 604.2MB 1.1MB/s eta 0:01:07    99% |███████████████████████████████▊| 671.0MB 1.5MB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /home/kamel/anaconda3/lib/python3.7/site-packages (from flair) (3.0.3)\n",
      "Collecting segtok>=1.5.7 (from flair)\n",
      "Collecting mpld3==0.3 (from flair)\n",
      "Collecting regex (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/2a/8dda8b5d603cf379dae79929fb0bb2300ba9debe96f92b30b79b7159aa1b/regex-2019.06.05.tar.gz (651kB)\n",
      "\u001b[K    100% |████████████████████████████████| 655kB 1.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting sklearn (from flair)\n",
      "Collecting gensim>=3.4.0 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/82/2542fac981c1f9302164127088bb2d2044bf70b18ed181bc745b4432f51a/gensim-3.7.3-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.2MB 948kB/s ta 0:00:011    77% |█████████████████████████       | 18.8MB 1.8MB/s eta 0:00:04    84% |███████████████████████████     | 20.4MB 1.5MB/s eta 0:00:03� | 23.2MB 29.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /home/kamel/anaconda3/lib/python3.7/site-packages (from flair) (4.31.1)\n",
      "Collecting bpemb>=0.2.9 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/57/90/8760eaa97c5a2f676f3f350fd43e79f8d9e4f9c42362c62f733e81e37d33/bpemb-0.2.12-py3-none-any.whl\n",
      "Requirement already satisfied: wrapt<2,>=1 in /home/kamel/anaconda3/lib/python3.7/site-packages (from deprecated>=1.2.4->flair) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/kamel/anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (2.2)\n",
      "Requirement already satisfied: future in /home/kamel/anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (0.17.1)\n",
      "Requirement already satisfied: scipy in /home/kamel/anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.2.1)\n",
      "Requirement already satisfied: six in /home/kamel/anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.12.0)\n",
      "Requirement already satisfied: numpy in /home/kamel/anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.16.2)\n",
      "Collecting pymongo (from hyperopt>=0.1.1->flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/f9/c748aa7807dafcc5eade282db46e16242b15dfe951da10ff434fd22ca282/pymongo-3.8.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: py>=1.5.0 in /home/kamel/anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
      "Requirement already satisfied: setuptools in /home/kamel/anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (40.8.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/kamel/anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (19.1.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /home/kamel/anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
      "Requirement already satisfied: pluggy>=0.7 in /home/kamel/anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (0.9.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /home/kamel/anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (6.0.0)\n",
      "Requirement already satisfied: requests in /home/kamel/anaconda3/lib/python3.7/site-packages (from pytorch-pretrained-bert>=0.6.1->flair) (2.21.0)\n",
      "Collecting boto3 (from pytorch-pretrained-bert>=0.6.1->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/c4/c910dc805eded2efe5f2dc84ae1c553a24d2c68969c1b0a172c2cbb54779/boto3-1.9.163-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 1.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /home/kamel/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/kamel/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/kamel/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/kamel/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /home/kamel/anaconda3/lib/python3.7/site-packages (from sklearn->flair) (0.20.3)\n",
      "Collecting smart-open>=1.7.0 (from gensim>=3.4.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/c0/25d19badc495428dec6a4bf7782de617ee0246a9211af75b302a2681dea7/smart_open-1.8.4.tar.gz (63kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 2.3MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting sentencepiece (from bpemb>=0.2.9->flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/ab/04/7a5015e3087c80037776b75e1a85517dc07f7203f234432a79c132a67dc3/sentencepiece-0.1.82-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/kamel/anaconda3/lib/python3.7/site-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/kamel/anaconda3/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kamel/anaconda3/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/kamel/anaconda3/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (3.0.4)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->pytorch-pretrained-bert>=0.6.1->flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from boto3->pytorch-pretrained-bert>=0.6.1->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 1.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.13.0,>=1.12.163 (from boto3->pytorch-pretrained-bert>=0.6.1->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/42/f601129ebb1c08249b3ea3e1db1074cd4f1b6e4e00eed7f6cebe5b2432d6/botocore-1.12.163-py2.py3-none-any.whl (5.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.5MB 1.4MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: boto>=2.32 in /home/kamel/anaconda3/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim>=3.4.0->flair) (2.49.0)\n",
      "Requirement already satisfied: docutils>=0.10 in /home/kamel/anaconda3/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.163->boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.14)\n",
      "Building wheels for collected packages: regex, smart-open\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/kamel/.cache/pip/wheels/49/35/7c/7faf4dc02cdad88d0388e0f895621a34479e1f17f9e4f4ee12\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/kamel/.cache/pip/wheels/5f/ea/fb/5b1a947b369724063b2617011f1540c44eb00e28c3d2ca8692\n",
      "Successfully built regex smart-open\n",
      "Installing collected packages: deprecated, sqlitedict, pymongo, hyperopt, tabulate, torch, regex, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, segtok, mpld3, sklearn, smart-open, gensim, sentencepiece, bpemb, flair\n",
      "Successfully installed boto3-1.9.163 botocore-1.12.163 bpemb-0.2.12 deprecated-1.2.5 flair-0.4.2 gensim-3.7.3 hyperopt-0.1.2 jmespath-0.9.4 mpld3-0.3 pymongo-3.8.0 pytorch-pretrained-bert-0.6.2 regex-2019.6.5 s3transfer-0.2.1 segtok-1.5.7 sentencepiece-0.1.82 sklearn-0.0 smart-open-1.8.4 sqlitedict-1.6.0 tabulate-0.8.3 torch-1.1.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 07:22:02,165 Reading data from .\n",
      "2019-06-07 07:22:02,165 Train: train.csv\n",
      "2019-06-07 07:22:02,166 Dev: dev.csv\n",
      "2019-06-07 07:22:02,167 Test: test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  \n",
      "/home/kamel/anaconda3/lib/python3.7/site-packages/flair/data_fetcher.py:447: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  max_tokens_per_doc=max_tokens_per_doc,\n",
      "/home/kamel/anaconda3/lib/python3.7/site-packages/flair/data_fetcher.py:454: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  max_tokens_per_doc=max_tokens_per_doc,\n",
      "/home/kamel/anaconda3/lib/python3.7/site-packages/flair/data_fetcher.py:463: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  max_tokens_per_doc=max_tokens_per_doc,\n"
     ]
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings,DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 07:22:11,868 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmp2w8v8jwf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160000128/160000128 [01:43<00:00, 1547940.86B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 07:23:55,516 copying /tmp/tmp2w8v8jwf to cache at /home/kamel/.flair/embeddings/glove.gensim.vectors.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 07:23:55,693 removing temp file /tmp/tmp2w8v8jwf\n",
      "2019-06-07 07:23:55,995 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmpb0p_j0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21494764/21494764 [00:13<00:00, 1569963.94B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 07:24:09,959 copying /tmp/tmpb0p_j0us to cache at /home/kamel/.flair/embeddings/glove.gensim\n",
      "2019-06-07 07:24:09,998 removing temp file /tmp/tmpb0p_j0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/kamel/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 07:24:11,176 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmp4132jtpk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19689779/19689779 [00:12<00:00, 1530396.94B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 07:24:24,330 copying /tmp/tmp4132jtpk to cache at /home/kamel/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
      "2019-06-07 07:24:24,359 removing temp file /tmp/tmp4132jtpk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 07:24:24,706 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpuwki4iap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19689779/19689779 [00:13<00:00, 1313288.99B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 07:24:38,249 copying /tmp/tmpuwki4iap to cache at /home/kamel/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
      "2019-06-07 07:24:38,275 removing temp file /tmp/tmpuwki4iap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = [WordEmbeddings('glove'),FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 07:25:40,126 {'advertising', 'agriculture'}\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(classifier, corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 07:25:46,698 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 07:25:46,700 Evaluation method: MICRO_F1_SCORE\n",
      "2019-06-07 07:25:46,853 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 07:26:56,878 epoch 1 - iter 0/5 - loss 0.72180063\n",
      "2019-06-07 07:28:56,936 epoch 1 - iter 1/5 - loss 0.69885233\n",
      "2019-06-07 07:30:02,982 epoch 1 - iter 2/5 - loss 0.67587783\n",
      "2019-06-07 07:31:38,795 epoch 1 - iter 3/5 - loss 0.65979837\n",
      "2019-06-07 07:32:31,116 epoch 1 - iter 4/5 - loss 0.63878593\n",
      "2019-06-07 07:32:31,335 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 07:32:31,336 EPOCH 1 done: loss 0.6388 - lr 0.1000 - bad epochs 0\n",
      "2019-06-07 07:33:10,875 DEV : loss 1.2981122732162476 - score 0.0\n",
      "2019-06-07 07:34:09,504 TEST : loss 1.3780931234359741 - score 0.0\n",
      "2019-06-07 07:34:12,750 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 07:35:38,177 epoch 2 - iter 0/5 - loss 0.64153624\n",
      "2019-06-07 07:38:10,290 epoch 2 - iter 1/5 - loss 0.64537603\n",
      "2019-06-07 07:39:51,358 epoch 2 - iter 2/5 - loss 0.62283673\n",
      "2019-06-07 07:41:41,275 epoch 2 - iter 3/5 - loss 0.63760611\n",
      "2019-06-07 07:42:16,758 epoch 2 - iter 4/5 - loss 0.59770028\n",
      "2019-06-07 07:42:17,070 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 07:42:17,071 EPOCH 2 done: loss 0.5977 - lr 0.1000 - bad epochs 0\n",
      "2019-06-07 07:42:48,165 DEV : loss 1.3286850452423096 - score 0.0\n",
      "2019-06-07 07:43:35,878 TEST : loss 1.4985607862472534 - score 0.0\n",
      "2019-06-07 07:43:38,681 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 07:46:07,059 epoch 3 - iter 0/5 - loss 0.62510979\n",
      "2019-06-07 07:47:31,246 epoch 3 - iter 1/5 - loss 0.60728046\n",
      "2019-06-07 07:49:04,710 epoch 3 - iter 2/5 - loss 0.56186439\n",
      "2019-06-07 07:51:00,956 epoch 3 - iter 3/5 - loss 0.56822204\n",
      "2019-06-07 07:51:31,053 epoch 3 - iter 4/5 - loss 0.53883833\n",
      "2019-06-07 07:51:31,386 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 07:51:31,387 EPOCH 3 done: loss 0.5388 - lr 0.1000 - bad epochs 1\n",
      "2019-06-07 07:52:05,726 DEV : loss 1.5224592685699463 - score 0.0\n",
      "2019-06-07 07:53:01,118 TEST : loss 1.7396899461746216 - score 0.0\n",
      "Epoch     2: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-06-07 07:53:04,405 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 07:55:24,140 epoch 4 - iter 0/5 - loss 0.63625795\n",
      "2019-06-07 07:57:07,062 epoch 4 - iter 1/5 - loss 0.60172501\n",
      "2019-06-07 07:58:39,169 epoch 4 - iter 2/5 - loss 0.58036168\n",
      "2019-06-07 08:00:36,484 epoch 4 - iter 3/5 - loss 0.54511773\n",
      "2019-06-07 08:01:40,112 epoch 4 - iter 4/5 - loss 0.56421317\n",
      "2019-06-07 08:01:40,542 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:01:40,543 EPOCH 4 done: loss 0.5642 - lr 0.0500 - bad epochs 0\n",
      "2019-06-07 08:02:16,612 DEV : loss 0.8037463426589966 - score 0.3889\n",
      "2019-06-07 08:03:10,542 TEST : loss 1.0153758525848389 - score 0.1667\n",
      "2019-06-07 08:03:13,976 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:05:45,080 epoch 5 - iter 0/5 - loss 0.61628294\n",
      "2019-06-07 08:07:18,267 epoch 5 - iter 1/5 - loss 0.52596004\n",
      "2019-06-07 08:09:06,783 epoch 5 - iter 2/5 - loss 0.51788097\n",
      "2019-06-07 08:10:24,004 epoch 5 - iter 3/5 - loss 0.50567611\n",
      "2019-06-07 08:10:49,162 epoch 5 - iter 4/5 - loss 0.47355327\n",
      "2019-06-07 08:10:49,551 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:10:49,552 EPOCH 5 done: loss 0.4736 - lr 0.0500 - bad epochs 0\n",
      "2019-06-07 08:11:26,525 DEV : loss 0.9107889533042908 - score 0.2778\n",
      "2019-06-07 08:12:25,080 TEST : loss 1.166557788848877 - score 0.1111\n",
      "2019-06-07 08:12:25,082 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:14:52,862 epoch 6 - iter 0/5 - loss 0.47473508\n",
      "2019-06-07 08:16:59,302 epoch 6 - iter 1/5 - loss 0.45108898\n",
      "2019-06-07 08:18:28,658 epoch 6 - iter 2/5 - loss 0.46307832\n",
      "2019-06-07 08:19:31,218 epoch 6 - iter 3/5 - loss 0.49230441\n",
      "2019-06-07 08:20:06,170 epoch 6 - iter 4/5 - loss 0.46558080\n",
      "2019-06-07 08:20:06,568 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:20:06,569 EPOCH 6 done: loss 0.4656 - lr 0.0500 - bad epochs 1\n",
      "2019-06-07 08:20:41,947 DEV : loss 0.8113716840744019 - score 0.4444\n",
      "2019-06-07 08:21:34,415 TEST : loss 1.0787675380706787 - score 0.1667\n",
      "2019-06-07 08:21:37,188 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:23:55,962 epoch 7 - iter 0/5 - loss 0.45434809\n",
      "2019-06-07 08:25:44,601 epoch 7 - iter 1/5 - loss 0.45791215\n",
      "2019-06-07 08:26:51,770 epoch 7 - iter 2/5 - loss 0.45934340\n",
      "2019-06-07 08:28:18,384 epoch 7 - iter 3/5 - loss 0.48459307\n",
      "2019-06-07 08:28:52,541 epoch 7 - iter 4/5 - loss 0.50056753\n",
      "2019-06-07 08:28:52,925 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:28:52,925 EPOCH 7 done: loss 0.5006 - lr 0.0500 - bad epochs 0\n",
      "2019-06-07 08:29:22,667 DEV : loss 0.8163462281227112 - score 0.3889\n",
      "2019-06-07 08:30:08,762 TEST : loss 1.0808851718902588 - score 0.1667\n",
      "2019-06-07 08:30:08,763 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:31:23,430 epoch 8 - iter 0/5 - loss 0.49729997\n",
      "2019-06-07 08:33:11,742 epoch 8 - iter 1/5 - loss 0.46095809\n",
      "2019-06-07 08:34:45,461 epoch 8 - iter 2/5 - loss 0.44865591\n",
      "2019-06-07 08:36:24,736 epoch 8 - iter 3/5 - loss 0.46427632\n",
      "2019-06-07 08:37:04,614 epoch 8 - iter 4/5 - loss 0.45463196\n",
      "2019-06-07 08:37:04,972 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:37:04,973 EPOCH 8 done: loss 0.4546 - lr 0.0500 - bad epochs 1\n",
      "2019-06-07 08:37:34,272 DEV : loss 0.7260242104530334 - score 0.5\n",
      "2019-06-07 08:38:21,400 TEST : loss 0.9996324181556702 - score 0.2778\n",
      "2019-06-07 08:38:23,901 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:39:40,048 epoch 9 - iter 0/5 - loss 0.52184832\n",
      "2019-06-07 08:41:03,990 epoch 9 - iter 1/5 - loss 0.48028435\n",
      "2019-06-07 08:42:51,983 epoch 9 - iter 2/5 - loss 0.45074291\n",
      "2019-06-07 08:43:42,443 epoch 9 - iter 3/5 - loss 0.43845981\n",
      "2019-06-07 08:44:21,979 epoch 9 - iter 4/5 - loss 0.43566878\n",
      "2019-06-07 08:44:22,246 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:44:22,247 EPOCH 9 done: loss 0.4357 - lr 0.0500 - bad epochs 0\n",
      "2019-06-07 08:44:51,367 DEV : loss 0.9011313319206238 - score 0.3333\n",
      "2019-06-07 08:45:36,823 TEST : loss 1.2068829536437988 - score 0.1667\n",
      "2019-06-07 08:45:36,824 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:46:50,682 epoch 10 - iter 0/5 - loss 0.49386761\n",
      "2019-06-07 08:48:42,531 epoch 10 - iter 1/5 - loss 0.45205496\n",
      "2019-06-07 08:49:41,238 epoch 10 - iter 2/5 - loss 0.46098801\n",
      "2019-06-07 08:50:46,328 epoch 10 - iter 3/5 - loss 0.46888737\n",
      "2019-06-07 08:51:36,888 epoch 10 - iter 4/5 - loss 0.45903701\n",
      "2019-06-07 08:51:37,207 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:51:37,208 EPOCH 10 done: loss 0.4590 - lr 0.0500 - bad epochs 1\n",
      "2019-06-07 08:52:04,805 DEV : loss 0.9353657960891724 - score 0.1667\n",
      "2019-06-07 08:52:51,959 TEST : loss 1.2475476264953613 - score 0.1667\n",
      "Epoch     9: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2019-06-07 08:52:54,518 ----------------------------------------------------------------------------------------------------\n",
      "2019-06-07 08:52:54,519 Testing using best model ...\n",
      "2019-06-07 08:52:54,521 loading file best-model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 08:53:42,090 0.2778\t0.2778\t0.2778\n",
      "2019-06-07 08:53:42,092 \n",
      "MICRO_AVG: acc 0.1613 - f1-score 0.2778\n",
      "MACRO_AVG: acc 0.1389 - f1-score 0.2174\n",
      "advertising tp: 0 - fp: 13 - fn: 0 - tn: 5 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "agriculture tp: 5 - fp: 0 - fn: 13 - tn: 0 - precision: 1.0000 - recall: 0.2778 - accuracy: 0.2778 - f1-score: 0.4348\n",
      "2019-06-07 08:53:42,093 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.2778,\n",
       " 'dev_score_history': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3889,\n",
       "  0.2778,\n",
       "  0.4444,\n",
       "  0.3889,\n",
       "  0.5,\n",
       "  0.3333,\n",
       "  0.1667],\n",
       " 'train_loss_history': [0.6387859344482422,\n",
       "  0.5977002799510955,\n",
       "  0.5388383269309998,\n",
       "  0.5642131745815278,\n",
       "  0.47355327010154724,\n",
       "  0.46558079719543455,\n",
       "  0.5005675256252289,\n",
       "  0.45463196039199827,\n",
       "  0.43566877841949464,\n",
       "  0.4590370118618011],\n",
       " 'dev_loss_history': [tensor(1.2981),\n",
       "  tensor(1.3287),\n",
       "  tensor(1.5225),\n",
       "  tensor(0.8037),\n",
       "  tensor(0.9108),\n",
       "  tensor(0.8114),\n",
       "  tensor(0.8163),\n",
       "  tensor(0.7260),\n",
       "  tensor(0.9011),\n",
       "  tensor(0.9354)]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train('./', max_epochs=10, patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
