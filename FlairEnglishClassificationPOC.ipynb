{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Flair Embedding and Glove over English dataset with 2 categories as a POC due to resources shortage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('/home/nesma/SemesterII/Neural Networks/Project/multilingual-text-categorization-dataset/data/dataset.csv', sep='\\t', header=None).applymap(str)\n",
    "dataset.columns = [\"Language\",\"label\",\"text\"]\n",
    "languagesData=[]\n",
    "loc = 0\n",
    "languages = dataset[dataset.columns[0]].unique()\n",
    "for i in languages:\n",
    "    name = languages[loc]+\"Data\" \n",
    "    globals()[name] = pd.DataFrame( dataset[dataset.Language == i])\n",
    "    loc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(englishData)\n",
    "englishData = englishData[1:180]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Language        label                                               text\n",
      "6   english  advertising  musk bid for tesla: no formal offer, no firm d...\n",
      "7   english  advertising  wall st. rallies on solid earnings, u.s.-china...\n",
      "8   english  advertising  iran says no opec member can take over its sha...\n",
      "9   english  advertising  online courses in data science that could help...\n",
      "10  english  advertising  vw's ceo was told about emissions software mon...\n"
     ]
    }
   ],
   "source": [
    "def lower_words(text):\n",
    "    text = text.str.lower()\n",
    "    return text\n",
    "\n",
    "englishData['text'] = lower_words(englishData['text'])\n",
    "input_str = englishData['text']\n",
    "print(englishData.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>musk bid for tesla: no formal offer, no firm d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>wall st. rallies on solid earnings, u.s.-china...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>iran says no opec member can take over its sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>online courses in data science that could help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>vw's ceo was told about emissions software mon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language        label                                               text\n",
       "6   english  advertising  musk bid for tesla: no formal offer, no firm d...\n",
       "7   english  advertising  wall st. rallies on solid earnings, u.s.-china...\n",
       "8   english  advertising  iran says no opec member can take over its sha...\n",
       "9   english  advertising  online courses in data science that could help...\n",
       "10  english  advertising  vw's ceo was told about emissions software mon..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "def remove_url(text):\n",
    "    text = text.apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "    return text\n",
    "\n",
    "\n",
    "englishData['text'] = remove_url(englishData['text'])\n",
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>musk bid for tesla: no formal offer, no firm d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>wall st. rallies on solid earnings, u.s.-china...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>iran says no opec member can take over its sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>online courses in data science that could help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>vw's ceo was told about emissions software mon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language        label                                               text\n",
       "6   english  advertising  musk bid for tesla: no formal offer, no firm d...\n",
       "7   english  advertising  wall st. rallies on solid earnings, u.s.-china...\n",
       "8   english  advertising  iran says no opec member can take over its sha...\n",
       "9   english  advertising  online courses in data science that could help...\n",
       "10  english  advertising  vw's ceo was told about emissions software mon..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_numbers(text):\n",
    "    text = text.str.replace('\\d+', '')\n",
    "    return text\n",
    "\n",
    "\n",
    "englishData['text'] = remove_numbers(englishData['text'])\n",
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>musk bid for tesla no formal offer no firm dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>wall st rallies on solid earnings uschina trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>iran says no opec member can take over its sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>online courses in data science that could help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>vws ceo was told about emissions software mont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language        label                                               text\n",
       "6   english  advertising  musk bid for tesla no formal offer no firm dea...\n",
       "7   english  advertising  wall st rallies on solid earnings uschina trad...\n",
       "8   english  advertising  iran says no opec member can take over its sha...\n",
       "9   english  advertising  online courses in data science that could help...\n",
       "10  english  advertising  vws ceo was told about emissions software mont..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuations(text):\n",
    "    text = text.str.replace('[^\\w\\s]','')\n",
    "    return text\n",
    "\n",
    "\n",
    "englishData['text'] = remove_punctuations(englishData['text'])\n",
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>musk bid for tesla no formal offer no firm dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>wall st rallies on solid earnings uschina trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>iran says no opec member can take over its sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>online courses in data science that could help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>vws ceo was told about emissions software mont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language        label                                               text\n",
       "6   english  advertising  musk bid for tesla no formal offer no firm dea...\n",
       "7   english  advertising  wall st rallies on solid earnings uschina trad...\n",
       "8   english  advertising  iran says no opec member can take over its sha...\n",
       "9   english  advertising  online courses in data science that could help...\n",
       "10  english  advertising  vws ceo was told about emissions software mont..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def remove_blank_space(col):\n",
    "    col = col.str.strip()\n",
    "    col = col.replace('\\s+', ' ', regex=True)   \n",
    "    return col\n",
    "\n",
    "\n",
    "englishData['text'] = remove_blank_space(englishData.text)\n",
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>musk bid for tesla no formal offer no firm dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>wall st rallies on solid earnings uschina trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>iran says no opec member can take over its sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>online courses in data science that could help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>vws ceo was told about emissions software mont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language        label                                               text\n",
       "6   english  advertising  musk bid for tesla no formal offer no firm dea...\n",
       "7   english  advertising  wall st rallies on solid earnings uschina trad...\n",
       "8   english  advertising  iran says no opec member can take over its sha...\n",
       "9   english  advertising  online courses in data science that could help...\n",
       "10  english  advertising  vws ceo was told about emissions software mont..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "def remove_stop_words(text, stop):    \n",
    "    text.apply(lambda x: [item for item in x if item not in stop])\n",
    "    return text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "remove_stop_words(englishData['text'],stop)\n",
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>musk bid for tesla no formal offer no firm dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>wall st ralli on solid earn uschina trade talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>iran say no opec member can take over it share...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>onlin cours in data scienc that could help you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>english</td>\n",
       "      <td>advertising</td>\n",
       "      <td>vw ceo wa told about emiss softwar month befor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language        label                                               text\n",
       "6   english  advertising  musk bid for tesla no formal offer no firm dea...\n",
       "7   english  advertising  wall st ralli on solid earn uschina trade talk...\n",
       "8   english  advertising  iran say no opec member can take over it share...\n",
       "9   english  advertising  onlin cours in data scienc that could help you...\n",
       "10  english  advertising  vw ceo wa told about emiss softwar month befor..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.split()\n",
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "englishData['text'] = englishData['text'].apply(stem_sentences)\n",
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishData = englishData[[\"label\",\"text\"]]\n",
    "englishData['label'] = '__label__' + englishData['label'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "englishData.iloc[0:int(len(englishData)*0.8)].to_csv('train.csv', sep='\\t', index = False, header = False)\n",
    "englishData.iloc[int(len(englishData)*0.8):int(len(englishData)*0.9)].to_csv('test.csv', sep='\\t', index = False, header = False)\n",
    "englishData.iloc[int(len(englishData)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>__label__advertising</td>\n",
       "      <td>musk bid for tesla no formal offer no firm dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>__label__advertising</td>\n",
       "      <td>wall st ralli on solid earn uschina trade talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>__label__advertising</td>\n",
       "      <td>iran say no opec member can take over it share...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>__label__advertising</td>\n",
       "      <td>onlin cours in data scienc that could help you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>__label__advertising</td>\n",
       "      <td>vw ceo wa told about emiss softwar month befor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label                                               text\n",
       "6   __label__advertising  musk bid for tesla no formal offer no firm dea...\n",
       "7   __label__advertising  wall st ralli on solid earn uschina trade talk...\n",
       "8   __label__advertising  iran say no opec member can take over it share...\n",
       "9   __label__advertising  onlin cours in data scienc that could help you...\n",
       "10  __label__advertising  vw ceo wa told about emiss softwar month befor..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-11 18:43:46,029 Reading data from .\n",
      "2019-05-11 18:43:46,030 Train: train.csv\n",
      "2019-05-11 18:43:46,031 Dev: dev.csv\n",
      "2019-05-11 18:43:46,031 Test: test.csv\n"
     ]
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings,DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = [WordEmbeddings('glove'),FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(classifier, corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-11 19:00:36,474 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:00:36,475 Evaluation method: MICRO_F1_SCORE\n",
      "2019-05-11 19:00:36,477 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:00:52,839 epoch 1 - iter 0/5 - loss 0.02151012\n",
      "2019-05-11 19:01:22,865 epoch 1 - iter 1/5 - loss 0.02015468\n",
      "2019-05-11 19:01:48,748 epoch 1 - iter 2/5 - loss 0.02130021\n",
      "2019-05-11 19:02:08,466 epoch 1 - iter 3/5 - loss 0.02173255\n",
      "2019-05-11 19:02:12,744 epoch 1 - iter 4/5 - loss 0.02510016\n",
      "2019-05-11 19:02:12,766 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:02:12,767 EPOCH 1 done: loss 0.0251 - lr 0.1000 - bad epochs 0\n",
      "2019-05-11 19:02:13,656 DEV  : loss 0.05333441 - f-score 0.0000 - acc 0.0000\n",
      "2019-05-11 19:02:14,340 TEST : loss 0.05473531 - f-score 0.0000 - acc 0.0000\n",
      "2019-05-11 19:02:17,402 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:02:37,890 epoch 2 - iter 0/5 - loss 0.01765242\n",
      "2019-05-11 19:03:06,823 epoch 2 - iter 1/5 - loss 0.01864944\n",
      "2019-05-11 19:03:24,921 epoch 2 - iter 2/5 - loss 0.01889908\n",
      "2019-05-11 19:03:40,976 epoch 2 - iter 3/5 - loss 0.01880079\n",
      "2019-05-11 19:03:48,672 epoch 2 - iter 4/5 - loss 0.02252774\n",
      "2019-05-11 19:03:48,710 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:03:48,711 EPOCH 2 done: loss 0.0225 - lr 0.1000 - bad epochs 0\n",
      "2019-05-11 19:03:49,538 DEV  : loss 0.09831058 - f-score 0.0000 - acc 0.0000\n",
      "2019-05-11 19:03:50,206 TEST : loss 0.09934720 - f-score 0.0000 - acc 0.0000\n",
      "2019-05-11 19:03:53,367 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:04:13,115 epoch 3 - iter 0/5 - loss 0.01967135\n",
      "2019-05-11 19:04:33,354 epoch 3 - iter 1/5 - loss 0.02006847\n",
      "2019-05-11 19:04:56,416 epoch 3 - iter 2/5 - loss 0.01960898\n",
      "2019-05-11 19:05:19,767 epoch 3 - iter 3/5 - loss 0.01897679\n",
      "2019-05-11 19:05:26,434 epoch 3 - iter 4/5 - loss 0.02236703\n",
      "2019-05-11 19:05:26,456 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:05:26,457 EPOCH 3 done: loss 0.0224 - lr 0.1000 - bad epochs 0\n",
      "2019-05-11 19:05:27,293 DEV  : loss 0.05681114 - f-score 0.0000 - acc 0.0000\n",
      "2019-05-11 19:05:27,962 TEST : loss 0.05808874 - f-score 0.0000 - acc 0.0000\n",
      "2019-05-11 19:05:31,315 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:05:51,347 epoch 4 - iter 0/5 - loss 0.01658209\n",
      "2019-05-11 19:06:12,291 epoch 4 - iter 1/5 - loss 0.01662149\n",
      "2019-05-11 19:06:39,283 epoch 4 - iter 2/5 - loss 0.01757070\n",
      "2019-05-11 19:06:59,143 epoch 4 - iter 3/5 - loss 0.01739656\n",
      "2019-05-11 19:07:02,251 epoch 4 - iter 4/5 - loss 0.02130843\n",
      "2019-05-11 19:07:02,274 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:07:02,276 EPOCH 4 done: loss 0.0213 - lr 0.1000 - bad epochs 0\n",
      "2019-05-11 19:07:03,286 DEV  : loss 0.05202954 - f-score 0.2222 - acc 0.1250\n",
      "2019-05-11 19:07:04,302 TEST : loss 0.05349473 - f-score 0.1667 - acc 0.0909\n",
      "2019-05-11 19:07:08,401 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:07:40,009 epoch 5 - iter 0/5 - loss 0.01686979\n",
      "2019-05-11 19:08:01,166 epoch 5 - iter 1/5 - loss 0.01624088\n",
      "2019-05-11 19:08:18,573 epoch 5 - iter 2/5 - loss 0.01740735\n",
      "2019-05-11 19:08:35,999 epoch 5 - iter 3/5 - loss 0.01684684\n",
      "2019-05-11 19:08:40,250 epoch 5 - iter 4/5 - loss 0.01984099\n",
      "2019-05-11 19:08:40,307 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:08:40,308 EPOCH 5 done: loss 0.0198 - lr 0.1000 - bad epochs 0\n",
      "2019-05-11 19:08:41,299 DEV  : loss 0.01808969 - f-score 0.9444 - acc 0.8947\n",
      "2019-05-11 19:08:41,982 TEST : loss 0.01949887 - f-score 0.9444 - acc 0.8947\n",
      "2019-05-11 19:08:44,924 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:09:09,459 epoch 6 - iter 0/5 - loss 0.02074005\n",
      "2019-05-11 19:09:26,703 epoch 6 - iter 1/5 - loss 0.02064536\n",
      "2019-05-11 19:09:52,029 epoch 6 - iter 2/5 - loss 0.01887758\n",
      "2019-05-11 19:10:07,656 epoch 6 - iter 3/5 - loss 0.01890662\n",
      "2019-05-11 19:10:14,904 epoch 6 - iter 4/5 - loss 0.02136232\n",
      "2019-05-11 19:10:14,917 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:10:14,921 EPOCH 6 done: loss 0.0214 - lr 0.1000 - bad epochs 0\n",
      "2019-05-11 19:10:15,779 DEV  : loss 0.02917197 - f-score 0.7778 - acc 0.6364\n",
      "2019-05-11 19:10:16,452 TEST : loss 0.02953706 - f-score 0.8333 - acc 0.7143\n",
      "2019-05-11 19:10:16,453 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:10:42,845 epoch 7 - iter 0/5 - loss 0.01686366\n",
      "2019-05-11 19:11:05,302 epoch 7 - iter 1/5 - loss 0.01503007\n",
      "2019-05-11 19:11:22,836 epoch 7 - iter 2/5 - loss 0.01534226\n",
      "2019-05-11 19:11:43,580 epoch 7 - iter 3/5 - loss 0.01506890\n",
      "2019-05-11 19:11:48,392 epoch 7 - iter 4/5 - loss 0.01795035\n",
      "2019-05-11 19:11:48,413 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:11:48,418 EPOCH 7 done: loss 0.0180 - lr 0.1000 - bad epochs 1\n",
      "2019-05-11 19:11:49,396 DEV  : loss 0.02270269 - f-score 0.8333 - acc 0.7143\n",
      "2019-05-11 19:11:50,078 TEST : loss 0.02214417 - f-score 0.8889 - acc 0.8000\n",
      "2019-05-11 19:11:53,272 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:12:17,296 epoch 8 - iter 0/5 - loss 0.01798918\n",
      "2019-05-11 19:12:36,617 epoch 8 - iter 1/5 - loss 0.01591835\n",
      "2019-05-11 19:12:58,499 epoch 8 - iter 2/5 - loss 0.01583739\n",
      "2019-05-11 19:13:19,223 epoch 8 - iter 3/5 - loss 0.01539600\n",
      "2019-05-11 19:13:23,442 epoch 8 - iter 4/5 - loss 0.01673860\n",
      "2019-05-11 19:13:23,462 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:13:23,465 EPOCH 8 done: loss 0.0167 - lr 0.1000 - bad epochs 0\n",
      "2019-05-11 19:13:24,320 DEV  : loss 0.03355251 - f-score 0.7778 - acc 0.6364\n",
      "2019-05-11 19:13:24,998 TEST : loss 0.03292181 - f-score 0.6667 - acc 0.5000\n",
      "2019-05-11 19:13:28,215 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:13:54,225 epoch 9 - iter 0/5 - loss 0.01470068\n",
      "2019-05-11 19:14:18,865 epoch 9 - iter 1/5 - loss 0.01359791\n",
      "2019-05-11 19:14:33,542 epoch 9 - iter 2/5 - loss 0.01365569\n",
      "2019-05-11 19:14:51,452 epoch 9 - iter 3/5 - loss 0.01420915\n",
      "2019-05-11 19:14:55,933 epoch 9 - iter 4/5 - loss 0.01566815\n",
      "2019-05-11 19:14:55,953 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:14:55,954 EPOCH 9 done: loss 0.0157 - lr 0.1000 - bad epochs 0\n",
      "2019-05-11 19:14:56,817 DEV  : loss 0.03192972 - f-score 0.7778 - acc 0.6364\n",
      "2019-05-11 19:14:57,495 TEST : loss 0.03168140 - f-score 0.6667 - acc 0.5000\n",
      "2019-05-11 19:15:00,656 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:15:19,360 epoch 10 - iter 0/5 - loss 0.01290440\n",
      "2019-05-11 19:15:35,211 epoch 10 - iter 1/5 - loss 0.01613067\n",
      "2019-05-11 19:16:05,012 epoch 10 - iter 2/5 - loss 0.01614517\n",
      "2019-05-11 19:16:27,035 epoch 10 - iter 3/5 - loss 0.01604863\n",
      "2019-05-11 19:16:30,680 epoch 10 - iter 4/5 - loss 0.02022501\n",
      "2019-05-11 19:16:30,695 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:16:30,697 EPOCH 10 done: loss 0.0202 - lr 0.1000 - bad epochs 0\n",
      "2019-05-11 19:16:31,563 DEV  : loss 0.16842233 - f-score 0.0000 - acc 0.0000\n",
      "2019-05-11 19:16:32,249 TEST : loss 0.15636598 - f-score 0.0000 - acc 0.0000\n",
      "2019-05-11 19:16:35,435 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-11 19:16:35,437 Testing using best model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-11 19:16:35,440 loading file best-model.pt\n",
      "2019-05-11 19:16:37,281 MICRO_AVG: acc 0.5 - f1-score 0.6667\n",
      "2019-05-11 19:16:37,282 MACRO_AVG: acc 0.3333 - f1-score 0.4\n",
      "2019-05-11 19:16:37,283 advertising tp: 0 - fp: 6 - fn: 0 - tn: 12 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-05-11 19:16:37,284 agriculture tp: 12 - fp: 0 - fn: 6 - tn: 0 - precision: 1.0000 - recall: 0.6667 - accuracy: 0.6667 - f1-score: 0.8000\n",
      "2019-05-11 19:16:37,285 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.6667,\n",
       " 'dev_score_history': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2222,\n",
       "  0.9444,\n",
       "  0.7778,\n",
       "  0.8333,\n",
       "  0.7778,\n",
       "  0.7778,\n",
       "  0.0],\n",
       " 'train_loss_history': [0.025100157103117776,\n",
       "  0.022527735899476445,\n",
       "  0.022367027314270243,\n",
       "  0.021308427786125857,\n",
       "  0.01984099320629064,\n",
       "  0.02136232199914315,\n",
       "  0.017950350966523674,\n",
       "  0.016738595550551134,\n",
       "  0.01566815420108683,\n",
       "  0.02022500686785754],\n",
       " 'dev_loss_history': [0.05333441123366356,\n",
       "  0.09831058233976364,\n",
       "  0.0568111352622509,\n",
       "  0.05202953889966011,\n",
       "  0.018089687451720238,\n",
       "  0.02917196974158287,\n",
       "  0.022702686488628387,\n",
       "  0.033552512526512146,\n",
       "  0.03192972391843796,\n",
       "  0.16842232644557953]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train('./', max_epochs=10, patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
