{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification all languages PHASE 1\n",
    "\n",
    "This dataset contains blog posts labeled by language and by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Languages  ['english' 'albanian' 'arabic' 'bulgarian' 'chinese' 'croatian' 'czech'\n",
      " 'danish' 'dutch' 'estonian' 'finnish' 'french' 'german' 'greek' 'hebrew'\n",
      " 'hungarian' 'icelandic' 'italian' 'japanese' 'korean' 'lithuanian'\n",
      " 'norwegian' 'polish' 'portuguese' 'romanian' 'russian' 'serbian'\n",
      " 'slovenian' 'spanish' 'swedish' 'turkish' 'ukrainian']\n",
      "45\n",
      "Categories ['advertising' 'agriculture' 'animation' 'arts_and_crafts' 'entertainment'\n",
      " 'astrology' 'vehicles' 'games' 'books_and_literature' 'business'\n",
      " 'gambling' 'jobs' 'clothing' 'comic_books' 'dating' 'education' 'adult'\n",
      " 'food' 'health' 'hobbies_and_interests' 'humor' 'illegal_content'\n",
      " 'investing' 'jewelry' 'logistics' 'marketing' 'movies' 'music' 'hacking'\n",
      " 'media' 'finance' 'pets' 'politics' 'religion' 'sci_fi_and_fantasy'\n",
      " 'science' 'shopping' 'society' 'sports' 'tech' 'teens' 'television'\n",
      " 'travel' 'under_construction' 'weather']\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/dataset.csv', sep='\\t', header=None).applymap(str)\n",
    "#Get the labels for languages\n",
    "languages = dataset[dataset.columns[0]].unique()\n",
    "print(\"Languages \",languages)\n",
    "#Show the labels for categories\n",
    "categories = dataset[dataset.columns[1]].unique()\n",
    "print(len(categories))\n",
    "print(\"Categories\",categories)\n",
    "#Rename Dataset Columns\n",
    "dataset.columns = [\"Language\",\"Label\",\"Text\"]\n",
    "dataset.head()\n",
    "#Encode the labels of the dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "dataset[\"Label\"] = label_encoder.fit_transform(dataset[\"Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a dataset for each language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "languagesData=[]\n",
    "loc = 0\n",
    "for i in languages:\n",
    "    name = languages[loc]+\"Data\" \n",
    "    globals()[name] = pd.DataFrame( dataset[dataset.Language == i])\n",
    "    loc += 1\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show sample from the datasets of french and spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "20169   french      1  Home / GEEK / Le gouvernement américain interd...\n",
      "20170   french      1  By OlivierLa puce la plus intéressante du lot ...\n",
      "20171   french      1  Home / PEOPLE / Mélanie Da Cruz maman : Anthon...\n",
      "20172   french      1  Arabie saoudite : plus de deux millions de fid...\n",
      "20173   french      1  21 août 2018 à 10h16 | Par El Mehdi BerradaMoh...\n",
      "      Language  Label                                               Text\n",
      "55590  spanish      1  CIUDAD DE MÉXICO (apro).- Miguel Ángel Marín, ...\n",
      "55591  spanish      1  Sigue la clausura de los Juegos Centroamerican...\n",
      "55592  spanish      1  CIUDAD DE MÉXICO (apro).- Gerardo Axel “N”, ub...\n",
      "55593  spanish      1  CIUDAD DE MÉXICO (apro).- En 2009, el movimien...\n",
      "55594  spanish      1  CIUDAD DE MÉXICO (apro).- El Instituto de Veri...\n"
     ]
    }
   ],
   "source": [
    "print(frenchData.head())\n",
    "print(spanishData.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the English dataset to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GRU,Dropout,BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "def myfunc(myDataset,shape):\n",
    "    print(myDataset.head())\n",
    "    X = myDataset.Text\n",
    "    Y = myDataset.Label\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(Y)\n",
    "\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
    "       X, Y, test_size=0.25, random_state=1000)\n",
    "\n",
    "    Ytrain = encoder.transform(Ytrain)\n",
    "    # convert integers to dummy variables (i.e. one hot encoded)\n",
    "    Ytrain = np_utils.to_categorical(Ytrain)\n",
    "\n",
    "    Ytest = encoder.transform(Ytest)\n",
    "    # convert integers to dummy variables (i.e. one hot encoded)\n",
    "    Ytest = np_utils.to_categorical(Ytest)\n",
    "\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=5000)\n",
    "    tokenizer.fit_on_texts(Xtrain)\n",
    "\n",
    "    Xtrain = tokenizer.texts_to_sequences(Xtrain)\n",
    "    Xtest = tokenizer.texts_to_sequences(Xtest)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "    maxlen = 100\n",
    "\n",
    "    Xtrain = pad_sequences(Xtrain, padding='post', maxlen=maxlen)\n",
    "    Xtest = pad_sequences(Xtest, padding='post', maxlen=maxlen)\n",
    "\n",
    "    print(Xtrain[0, :])\n",
    "    print(Ytrain)\n",
    "\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras import layers\n",
    "\n",
    "    embedding_dim = 50\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                               output_dim=embedding_dim, \n",
    "                               input_length=maxlen))\n",
    "\n",
    "    model.add(GRU(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(layers.Dense(shape, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(Xtrain, Ytrain,\n",
    "                        epochs=10,\n",
    "                        verbose=True,\n",
    "                        validation_data=(Xtest, Ytest))\n",
    "    loss, accuracy = model.evaluate(Xtrain, Ytrain, verbose=True)\n",
    "    print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "    loss, accuracy = model.evaluate(Xtest, Ytest, verbose=True)\n",
    "    print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helping function for plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "20169   french      1  Home / GEEK / Le gouvernement américain interd...\n",
      "20170   french      1  By OlivierLa puce la plus intéressante du lot ...\n",
      "20171   french      1  Home / PEOPLE / Mélanie Da Cruz maman : Anthon...\n",
      "20172   french      1  Arabie saoudite : plus de deux millions de fid...\n",
      "20173   french      1  21 août 2018 à 10h16 | Par El Mehdi BerradaMoh...\n",
      "[  24   89   63   15   44 1469  842   11 1073   14   35 1342   47  130\n",
      "    2   84    2   84    1  363   21    3    6 1480  292  484 1074 1523\n",
      "    9    1 1144  664 1730  679    9 2227  298  135   37 1427  363    3\n",
      "   45    8  780    2 1710   48   28  266  999  534    1 3100  193  327\n",
      "   20  197    1  103  367  958   59  814    3    1 1219    5   12  775\n",
      "    5    2  424   11  565  487   10    6 2707  105   71  341  196   34\n",
      "  116    6  236   86  261   48   33  445    7  920   20  377    1    2\n",
      "  897 4796]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 50)           3666850   \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 41)                10537     \n",
      "=================================================================\n",
      "Total params: 3,913,163\n",
      "Trainable params: 3,913,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2904 samples, validate on 969 samples\n",
      "Epoch 1/10\n",
      "2904/2904 [==============================] - 19s 7ms/step - loss: 3.6221 - acc: 0.0682 - val_loss: 3.5303 - val_acc: 0.0991\n",
      "Epoch 2/10\n",
      "2904/2904 [==============================] - 18s 6ms/step - loss: 3.4840 - acc: 0.0954 - val_loss: 3.4484 - val_acc: 0.1249\n",
      "Epoch 3/10\n",
      "2904/2904 [==============================] - 17s 6ms/step - loss: 3.2711 - acc: 0.1322 - val_loss: 3.2315 - val_acc: 0.1940\n",
      "Epoch 4/10\n",
      "2904/2904 [==============================] - 17s 6ms/step - loss: 2.9246 - acc: 0.2090 - val_loss: 3.0606 - val_acc: 0.2477\n",
      "Epoch 5/10\n",
      "2904/2904 [==============================] - 18s 6ms/step - loss: 2.5350 - acc: 0.3099 - val_loss: 2.9487 - val_acc: 0.2807\n",
      "Epoch 6/10\n",
      "2904/2904 [==============================] - 18s 6ms/step - loss: 2.1949 - acc: 0.4022 - val_loss: 2.9579 - val_acc: 0.2776\n",
      "Epoch 7/10\n",
      "2904/2904 [==============================] - 18s 6ms/step - loss: 1.9717 - acc: 0.4666 - val_loss: 2.9304 - val_acc: 0.2910\n",
      "Epoch 8/10\n",
      "2904/2904 [==============================] - 17s 6ms/step - loss: 1.7107 - acc: 0.5306 - val_loss: 2.9108 - val_acc: 0.3117\n",
      "Epoch 9/10\n",
      "2904/2904 [==============================] - 17s 6ms/step - loss: 1.5274 - acc: 0.5665 - val_loss: 2.9900 - val_acc: 0.3148\n",
      "Epoch 10/10\n",
      "2904/2904 [==============================] - 18s 6ms/step - loss: 1.3316 - acc: 0.6160 - val_loss: 2.9894 - val_acc: 0.3251\n",
      "2904/2904 [==============================] - 4s 1ms/step\n",
      "Training Accuracy: 0.6794\n",
      "969/969 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.3251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f1812a45588>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(frenchData,41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "55590  spanish      1  CIUDAD DE MÉXICO (apro).- Miguel Ángel Marín, ...\n",
      "55591  spanish      1  Sigue la clausura de los Juegos Centroamerican...\n",
      "55592  spanish      1  CIUDAD DE MÉXICO (apro).- Gerardo Axel “N”, ub...\n",
      "55593  spanish      1  CIUDAD DE MÉXICO (apro).- En 2009, el movimien...\n",
      "55594  spanish      1  CIUDAD DE MÉXICO (apro).- El Instituto de Veri...\n",
      "[  52    8  268  308    8  918    3   11    4    5    1 3966  210   13\n",
      "    7  258 3616   64 2105 2787    8  638  175    5    7   25  257    6\n",
      "    4 1342    7   30  232   73   13 1080 3244  175    5   10 2240    4\n",
      "    5  260 3865   11   82  639    3 2838   14   13 3964    4    5  257\n",
      "    6    2 1772    1  711    1    9   10  291    7    8  767 3065    4\n",
      "    5  179    1 2372 3067    2 2528    1  489 1010   11 1690    4  308\n",
      "    8  952   13   10  175    2  960    1   13    1    2    4    5   70\n",
      "    1  996]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 100, 50)           4133700   \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 42)                10794     \n",
      "=================================================================\n",
      "Total params: 4,380,270\n",
      "Trainable params: 4,380,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3030 samples, validate on 1010 samples\n",
      "Epoch 1/10\n",
      "3030/3030 [==============================] - 19s 6ms/step - loss: 3.6707 - acc: 0.0657 - val_loss: 3.5989 - val_acc: 0.0772\n",
      "Epoch 2/10\n",
      "3030/3030 [==============================] - 19s 6ms/step - loss: 3.4977 - acc: 0.0941 - val_loss: 3.4995 - val_acc: 0.0960\n",
      "Epoch 3/10\n",
      "3030/3030 [==============================] - 18s 6ms/step - loss: 3.2255 - acc: 0.1264 - val_loss: 3.3538 - val_acc: 0.1436\n",
      "Epoch 4/10\n",
      "3030/3030 [==============================] - 18s 6ms/step - loss: 2.7766 - acc: 0.2647 - val_loss: 3.1002 - val_acc: 0.2614\n",
      "Epoch 5/10\n",
      "3030/3030 [==============================] - 18s 6ms/step - loss: 2.3458 - acc: 0.3693 - val_loss: 2.9777 - val_acc: 0.2842\n",
      "Epoch 6/10\n",
      "3030/3030 [==============================] - 18s 6ms/step - loss: 1.9900 - acc: 0.4591 - val_loss: 3.0712 - val_acc: 0.2980\n",
      "Epoch 7/10\n",
      "3030/3030 [==============================] - 18s 6ms/step - loss: 1.6575 - acc: 0.5469 - val_loss: 3.0102 - val_acc: 0.3149\n",
      "Epoch 8/10\n",
      "3030/3030 [==============================] - 18s 6ms/step - loss: 1.4164 - acc: 0.6050 - val_loss: 3.0712 - val_acc: 0.3238\n",
      "Epoch 9/10\n",
      "3030/3030 [==============================] - 18s 6ms/step - loss: 1.2344 - acc: 0.6627 - val_loss: 3.1633 - val_acc: 0.3396\n",
      "Epoch 10/10\n",
      "3030/3030 [==============================] - 18s 6ms/step - loss: 1.0350 - acc: 0.7112 - val_loss: 3.2434 - val_acc: 0.3455\n",
      "3030/3030 [==============================] - 4s 1ms/step\n",
      "Training Accuracy: 0.7630\n",
      "1010/1010 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.3455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f1826767080>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(spanishData,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Language  Label                                               Text\n",
      "5091   arabic     12  تشاهدونا اليوم علي قناة ON Sport 2 مباريات الد...\n",
      "5092   arabic     12  سِنغري يسأل هواسا عن عضوها المفضل من Big Bang!...\n",
      "5093   arabic     12  يعنى ضاضا كان بيحترم الدولة ودلوقتى مبقاش يحتر...\n",
      "5094   arabic     12  بارك بوم تحيي معجبيها كفنانة من وكالة D Nation...\n",
      "5095   arabic     12  تشكيل فريقي نجوم إف سي والمقاولون العرب لمواجه...\n",
      "[  82  637 3181  105   82   39   82 1180   82 1144 1027   82   13   64\n",
      "   97 4444  318   39   82   13  338  338   16   82  157 2170   16   82\n",
      " 3559   16   82 2397   16   82 1265 2273   16   82 2858 2060   16   82\n",
      "   64  123   16   82 3820   16   82 1459 3361   16   82 1800   16   82\n",
      " 4445   16   82 4446   16   82 3821   82 1359   16   82 2648   16   82\n",
      " 1712   16   82  157 2274   16   82  637 3181  105   82   39   82 1180\n",
      "   82 1144 1027 1521 1357 1143 1358 1356 1357 1143 1358 1356 1357 1143\n",
      " 1358 1356]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 100, 50)           3300100   \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 28)                7196      \n",
      "=================================================================\n",
      "Total params: 3,543,072\n",
      "Trainable params: 3,543,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1494 samples, validate on 498 samples\n",
      "Epoch 1/10\n",
      "1494/1494 [==============================] - 9s 6ms/step - loss: 3.2299 - acc: 0.0810 - val_loss: 3.0982 - val_acc: 0.0763\n",
      "Epoch 2/10\n",
      "1494/1494 [==============================] - 8s 6ms/step - loss: 3.0724 - acc: 0.1004 - val_loss: 3.0112 - val_acc: 0.0763\n",
      "Epoch 3/10\n",
      "1494/1494 [==============================] - 8s 6ms/step - loss: 2.9623 - acc: 0.1058 - val_loss: 2.9266 - val_acc: 0.0944\n",
      "Epoch 4/10\n",
      "1494/1494 [==============================] - 8s 6ms/step - loss: 2.8343 - acc: 0.1466 - val_loss: 2.7654 - val_acc: 0.1305\n",
      "Epoch 5/10\n",
      "1494/1494 [==============================] - 8s 6ms/step - loss: 2.6484 - acc: 0.1961 - val_loss: 2.8698 - val_acc: 0.2249\n",
      "Epoch 6/10\n",
      "1494/1494 [==============================] - 8s 6ms/step - loss: 2.5132 - acc: 0.2644 - val_loss: 2.5641 - val_acc: 0.2369\n",
      "Epoch 7/10\n",
      "1494/1494 [==============================] - 9s 6ms/step - loss: 2.2462 - acc: 0.2925 - val_loss: 2.4663 - val_acc: 0.2590\n",
      "Epoch 8/10\n",
      "1494/1494 [==============================] - 10s 7ms/step - loss: 2.0699 - acc: 0.3327 - val_loss: 2.5104 - val_acc: 0.2470\n",
      "Epoch 9/10\n",
      "1494/1494 [==============================] - 9s 6ms/step - loss: 1.9645 - acc: 0.3809 - val_loss: 2.4384 - val_acc: 0.2751\n",
      "Epoch 10/10\n",
      "1494/1494 [==============================] - 9s 6ms/step - loss: 1.7966 - acc: 0.4317 - val_loss: 2.4462 - val_acc: 0.2691\n",
      "1494/1494 [==============================] - 2s 1ms/step\n",
      "Training Accuracy: 0.4411\n",
      "498/498 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.2691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f1812c590b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(arabicData,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language  Label                                               Text\n",
      "0  english      1  Exclusive: U.S. government seeks Facebook help...\n",
      "1  english      1  Trump asks SEC to mull half-year corporate fil...\n",
      "2  english      1  Wall St. up on trade hopes, S&P equals longest...\n",
      "3  english      1  Asian shares hit one-year low on Turkey, China...\n",
      "4  english      1  Asian stocks weaken as Turkey worries weigh, d...\n",
      "[   4   51  318 1388   12  596 1388 1445    5    4    1   44 1801 4255\n",
      "  836    2  227  178    6    1  200  156    3 2844 1275  384    1 2772\n",
      "   12   91 1244 1388  693    1   81  566    6  469    2   25  397  192\n",
      " 1037 1244   11    1  743  593 2081 1960  902 1961   51  798  869  873\n",
      "  351    4 1153 1678    6 1817   60  180   51   98 1244    1 1061   52\n",
      "  924 3998   22 1041    1 1488  146  117 2422   17   71   63  381    3\n",
      "  381    3 1116   11   17   49   13 3289 2265  681 2650   44  421 3999\n",
      "    1 3933]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 100, 50)           3867850   \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 45)                11565     \n",
      "=================================================================\n",
      "Total params: 4,115,191\n",
      "Trainable params: 4,115,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3389 samples, validate on 1130 samples\n",
      "Epoch 1/10\n",
      "3389/3389 [==============================] - 21s 6ms/step - loss: 3.7738 - acc: 0.0505 - val_loss: 3.7176 - val_acc: 0.0575\n",
      "Epoch 2/10\n",
      "3389/3389 [==============================] - 20s 6ms/step - loss: 3.6529 - acc: 0.0794 - val_loss: 3.5958 - val_acc: 0.0965\n",
      "Epoch 3/10\n",
      "3389/3389 [==============================] - 20s 6ms/step - loss: 3.4059 - acc: 0.1127 - val_loss: 3.4155 - val_acc: 0.1053\n",
      "Epoch 4/10\n",
      "3389/3389 [==============================] - 20s 6ms/step - loss: 3.0819 - acc: 0.1322 - val_loss: 3.2482 - val_acc: 0.1442\n",
      "Epoch 5/10\n",
      "3389/3389 [==============================] - 20s 6ms/step - loss: 2.6713 - acc: 0.2703 - val_loss: 3.1065 - val_acc: 0.1956\n",
      "Epoch 6/10\n",
      "3389/3389 [==============================] - 21s 6ms/step - loss: 2.1978 - acc: 0.3860 - val_loss: 3.0417 - val_acc: 0.2434\n",
      "Epoch 7/10\n",
      "3389/3389 [==============================] - 20s 6ms/step - loss: 1.8234 - acc: 0.4798 - val_loss: 3.0754 - val_acc: 0.2602\n",
      "Epoch 8/10\n",
      "3389/3389 [==============================] - 20s 6ms/step - loss: 1.5350 - acc: 0.5603 - val_loss: 3.2342 - val_acc: 0.2743\n",
      "Epoch 9/10\n",
      "3389/3389 [==============================] - 21s 6ms/step - loss: 1.2901 - acc: 0.6185 - val_loss: 3.2589 - val_acc: 0.2850\n",
      "Epoch 10/10\n",
      "3389/3389 [==============================] - 20s 6ms/step - loss: 1.1276 - acc: 0.6636 - val_loss: 3.3875 - val_acc: 0.2832\n",
      "3389/3389 [==============================] - 4s 1ms/step\n",
      "Training Accuracy: 0.7176\n",
      "1130/1130 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.2832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17da23f6d8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(englishData,45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Another model to increace accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language  Label                                               Text\n",
      "0  english      1  Exclusive: U.S. government seeks Facebook help...\n",
      "1  english      1  Trump asks SEC to mull half-year corporate fil...\n",
      "2  english      1  Wall St. up on trade hopes, S&P equals longest...\n",
      "3  english      1  Asian shares hit one-year low on Turkey, China...\n",
      "4  english      1  Asian stocks weaken as Turkey worries weigh, d...\n",
      "[   4   51  318 1388   12  596 1388 1445    5    4    1   44 1801 4255\n",
      "  836    2  227  178    6    1  200  156    3 2844 1275  384    1 2772\n",
      "   12   91 1244 1388  693    1   81  566    6  469    2   25  397  192\n",
      " 1037 1244   11    1  743  593 2081 1960  902 1961   51  798  869  873\n",
      "  351    4 1153 1678    6 1817   60  180   51   98 1244    1 1061   52\n",
      "  924 3998   22 1041    1 1488  146  117 2422   17   71   63  381    3\n",
      "  381    3 1116   11   17   49   13 3289 2265  681 2650   44  421 3999\n",
      "    1 3933]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 100, 50)           3867850   \n",
      "_________________________________________________________________\n",
      "gru_14 (GRU)                 (None, 100, 256)          235776    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100, 256)          65792     \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (None, 256)               393984    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 45)                11565     \n",
      "=================================================================\n",
      "Total params: 4,574,967\n",
      "Trainable params: 4,574,967\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3389 samples, validate on 1130 samples\n",
      "Epoch 1/10\n",
      "3389/3389 [==============================] - 42s 13ms/step - loss: 3.7493 - acc: 0.0508 - val_loss: 3.6604 - val_acc: 0.0531\n",
      "Epoch 2/10\n",
      "3389/3389 [==============================] - 40s 12ms/step - loss: 3.4407 - acc: 0.0823 - val_loss: 3.4570 - val_acc: 0.0770\n",
      "Epoch 3/10\n",
      "3389/3389 [==============================] - 43s 13ms/step - loss: 3.0831 - acc: 0.1192 - val_loss: 3.3653 - val_acc: 0.1283\n",
      "Epoch 4/10\n",
      "3389/3389 [==============================] - 41s 12ms/step - loss: 2.7117 - acc: 0.2098 - val_loss: 3.2559 - val_acc: 0.1779\n",
      "Epoch 5/10\n",
      "3389/3389 [==============================] - 41s 12ms/step - loss: 2.3171 - acc: 0.2904 - val_loss: 3.1632 - val_acc: 0.2283\n",
      "Epoch 6/10\n",
      "3389/3389 [==============================] - 41s 12ms/step - loss: 1.9574 - acc: 0.3880 - val_loss: 3.2900 - val_acc: 0.2469\n",
      "Epoch 7/10\n",
      "3389/3389 [==============================] - 41s 12ms/step - loss: 1.6216 - acc: 0.4777 - val_loss: 3.2435 - val_acc: 0.2628\n",
      "Epoch 8/10\n",
      "3389/3389 [==============================] - 41s 12ms/step - loss: 1.3289 - acc: 0.5668 - val_loss: 3.3294 - val_acc: 0.2796\n",
      "Epoch 9/10\n",
      "3389/3389 [==============================] - 41s 12ms/step - loss: 1.1095 - acc: 0.6368 - val_loss: 3.4561 - val_acc: 0.2823\n",
      "Epoch 10/10\n",
      "3389/3389 [==============================] - 41s 12ms/step - loss: 0.9244 - acc: 0.7011 - val_loss: 3.5651 - val_acc: 0.2858\n",
      "3389/3389 [==============================] - 10s 3ms/step\n",
      "Training Accuracy: 0.7796\n",
      "1130/1130 [==============================] - 3s 3ms/step\n",
      "Testing Accuracy:  0.2858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17d90c4358>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(englishData,45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Language  Label                                               Text\n",
      "7083  bulgarian     12  По-скъпа \"Гражданска\"... Справедливо ли ще е? ...\n",
      "7084  bulgarian     12  Абонамент по имейл за публикациите в Alex Deve...\n",
      "7085  bulgarian     12  Промо код PAKTA или PAKTA-TECH за 10%(всичко) ...\n",
      "7086  bulgarian     12  Заклещени в шахта! Пожарникари спасиха четири ...\n",
      "7087  bulgarian     12  Къде и за колко: Най-търсените имоти в големит...\n",
      "[   1 3015  371    7  640    3  641    1 1955 2103   31  257    8   34\n",
      "    3  288    8 2487 1287    1 1004 1389  876    4  653    2  451    1\n",
      " 3015   22 1955 2103    2    1 1127  304    4  469    1 2716   29 2267\n",
      "   20  243 3818    1   17 1551 2268  346 1044   42 1743 2716   20  120\n",
      " 4357 4358   20 1389  721  410    1  582  627    4 2105  877   19   76\n",
      " 3819    1 1045  424    9   14  364    4  384 1288    1  159  810    2\n",
      "  285  810    4    5  559    4   77  292  601  562  642    4  424  296\n",
      "    4  480]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 100, 50)           1498850   \n",
      "_________________________________________________________________\n",
      "gru_21 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 18)                4626      \n",
      "=================================================================\n",
      "Total params: 1,739,252\n",
      "Trainable params: 1,739,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 864 samples, validate on 288 samples\n",
      "Epoch 1/10\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 2.6970 - acc: 0.1586 - val_loss: 2.4391 - val_acc: 0.1771\n",
      "Epoch 2/10\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.4386 - acc: 0.1725 - val_loss: 2.3947 - val_acc: 0.1771\n",
      "Epoch 3/10\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.3181 - acc: 0.1725 - val_loss: 2.1746 - val_acc: 0.1771\n",
      "Epoch 4/10\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 2.1087 - acc: 0.1655 - val_loss: 2.1677 - val_acc: 0.1667\n",
      "Epoch 5/10\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.9753 - acc: 0.1806 - val_loss: 1.9580 - val_acc: 0.2188\n",
      "Epoch 6/10\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.7769 - acc: 0.2465 - val_loss: 1.8133 - val_acc: 0.2465\n",
      "Epoch 7/10\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.5381 - acc: 0.4954 - val_loss: 1.6435 - val_acc: 0.4236\n",
      "Epoch 8/10\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.3401 - acc: 0.5613 - val_loss: 1.5392 - val_acc: 0.4444\n",
      "Epoch 9/10\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.1629 - acc: 0.6134 - val_loss: 1.5094 - val_acc: 0.4931\n",
      "Epoch 10/10\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 1.0498 - acc: 0.6366 - val_loss: 1.5228 - val_acc: 0.5104\n",
      "864/864 [==============================] - 1s 1ms/step\n",
      "Training Accuracy: 0.6794\n",
      "288/288 [==============================] - 0s 1ms/step\n",
      "Testing Accuracy:  0.5104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17d92eba90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(bulgarianData,18) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Language  Label                                               Text\n",
      "8235  chinese      1  Aug 29, 2018 2018年7月成功出海的中国手游收入排名TOP30：《王国纪元》重...\n",
      "8236  chinese     12  飞鸟企业云精心为您打造企业云存储产品，为您提供了安全、稳定、高效的数据传输、备份、管理服务，...\n",
      "8237  chinese     12  身师快速设计手稿，草图，1.0版本包括Old school、Newschool、新传统、日式...\n",
      "8238  chinese     12  深驾是以自驾游为核心的互联网旅行品牌，定位于追求旅行品质的旅行者，打造量身定制、深度纯玩的旅...\n",
      "8239  chinese     12  服务大众！惠及大众！畅充科技是“新便民”生活和出行理念的开创者和领导者，本着便民、惠民为本的...\n",
      "[1286 1287   41  309 1288  525   63   53   57   54    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 100, 50)           730400    \n",
      "_________________________________________________________________\n",
      "gru_23 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 24)                6168      \n",
      "=================================================================\n",
      "Total params: 972,344\n",
      "Trainable params: 972,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1105 samples, validate on 369 samples\n",
      "Epoch 1/10\n",
      "1105/1105 [==============================] - 7s 6ms/step - loss: 2.9531 - acc: 0.1267 - val_loss: 2.8062 - val_acc: 0.1192\n",
      "Epoch 2/10\n",
      "1105/1105 [==============================] - 5s 4ms/step - loss: 2.7407 - acc: 0.1367 - val_loss: 2.7544 - val_acc: 0.1192\n",
      "Epoch 3/10\n",
      "1105/1105 [==============================] - 5s 4ms/step - loss: 2.7496 - acc: 0.1357 - val_loss: 2.7663 - val_acc: 0.1192\n",
      "Epoch 4/10\n",
      "1105/1105 [==============================] - 5s 4ms/step - loss: 2.8402 - acc: 0.1149 - val_loss: 2.8160 - val_acc: 0.0623\n",
      "Epoch 5/10\n",
      "1105/1105 [==============================] - 5s 4ms/step - loss: 2.7622 - acc: 0.1023 - val_loss: 2.8038 - val_acc: 0.1192\n",
      "Epoch 6/10\n",
      "1105/1105 [==============================] - 5s 4ms/step - loss: 2.7219 - acc: 0.1149 - val_loss: 2.7679 - val_acc: 0.0976\n",
      "Epoch 7/10\n",
      "1105/1105 [==============================] - 5s 4ms/step - loss: 2.6850 - acc: 0.0968 - val_loss: 2.7273 - val_acc: 0.0867\n",
      "Epoch 8/10\n",
      "1105/1105 [==============================] - 5s 5ms/step - loss: 2.6807 - acc: 0.0941 - val_loss: 2.7007 - val_acc: 0.0921\n",
      "Epoch 9/10\n",
      "1105/1105 [==============================] - 5s 4ms/step - loss: 2.6788 - acc: 0.0914 - val_loss: 2.7354 - val_acc: 0.0759\n",
      "Epoch 10/10\n",
      "1105/1105 [==============================] - 5s 4ms/step - loss: 2.6753 - acc: 0.1050 - val_loss: 2.6815 - val_acc: 0.1192\n",
      "1105/1105 [==============================] - 1s 1ms/step\n",
      "Training Accuracy: 0.1357\n",
      "369/369 [==============================] - 0s 1ms/step\n",
      "Testing Accuracy:  0.1192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17da1d4978>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(chineseData,24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "9709  croatian      1  Preminula žena koja je pronađena bez svesti na...\n",
      "9710  croatian      1  Folkloraši iz zemlje i regiona nastupaju u Med...\n",
      "9711  croatian      1  Vranjanac poginuo dok je prelazio prugu by Adm...\n",
      "9712  croatian      1  Droga i devize u donjem vešu i salveti by Admi...\n",
      "9713  croatian      1  Urednici “Jugpresa” pretili “surovim progonom”...\n",
      "[  97  422   78 2323    2  214  519    5 3158  155    1    8  214  110\n",
      " 1016  673    6    3 1090 2324    8    5   10   67   72    4 4142 1183\n",
      "   11    8  158   10   37   10  210 1091 4143    8    3 1493   26 2323\n",
      "  103 2324   51    2 4144  251 1091    1    2 1184   29    2    3  186\n",
      "  275  223 4145 1017  297    4    2  335  282  820  445   93   20 1422\n",
      "  594   15    2  254 3775   98   14 4598   85  119    2   21    2 2324\n",
      " 1359    5   10   37   10  539    1   26   84    2   37   10  427  133\n",
      " 1018 4599]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 100, 50)           2573850   \n",
      "_________________________________________________________________\n",
      "gru_25 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 29)                7453      \n",
      "=================================================================\n",
      "Total params: 2,817,079\n",
      "Trainable params: 2,817,079\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1125 samples, validate on 376 samples\n",
      "Epoch 1/10\n",
      "1125/1125 [==============================] - 10s 9ms/step - loss: 3.0813 - acc: 0.1280 - val_loss: 2.9154 - val_acc: 0.1197\n",
      "Epoch 2/10\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 2.8388 - acc: 0.1378 - val_loss: 2.8648 - val_acc: 0.1197\n",
      "Epoch 3/10\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 2.7856 - acc: 0.1378 - val_loss: 2.7487 - val_acc: 0.1197\n",
      "Epoch 4/10\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 2.6316 - acc: 0.1378 - val_loss: 2.6464 - val_acc: 0.1197\n",
      "Epoch 5/10\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 2.4965 - acc: 0.1387 - val_loss: 2.5870 - val_acc: 0.1197\n",
      "Epoch 6/10\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 2.3356 - acc: 0.1724 - val_loss: 2.4604 - val_acc: 0.1968\n",
      "Epoch 7/10\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 2.0557 - acc: 0.2898 - val_loss: 2.3147 - val_acc: 0.2793\n",
      "Epoch 8/10\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.8229 - acc: 0.4213 - val_loss: 2.1921 - val_acc: 0.2660\n",
      "Epoch 9/10\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5513 - acc: 0.4818 - val_loss: 2.1670 - val_acc: 0.3032\n",
      "Epoch 10/10\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.4766 - acc: 0.4747 - val_loss: 2.1207 - val_acc: 0.3059\n",
      "1125/1125 [==============================] - 2s 2ms/step\n",
      "Training Accuracy: 0.5164\n",
      "376/376 [==============================] - 1s 2ms/step\n",
      "Testing Accuracy:  0.3059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17c9f9a588>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(croatianData,29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "11210    czech      4  Friday, September 14th, 2018 at 1:00 PM - Prat...\n",
      "11211    czech     12  00:06:00 Přišli Bójové ze Slezska do Čech ve 4...\n",
      "11212    czech     12  00:00:05 Česká televize uvádí francouzský doku...\n",
      "11213    czech     12  00:09:53 S tím, že tam mají obrovské množství ...\n",
      "11214    czech     12  00:43:44 Co je? Antoníne! Co ti je?00:43:50 An...\n",
      "[  20  645 3940   19  733  278 2741 1512    5 2080  988 1129   11  331\n",
      "  298  253 2915    1 1033 1999   12  485 2490 2172    8  565    3 3716\n",
      "   33   31   21  264 4233    4 1294  219  677  765    6 3940   17  118\n",
      "   53  212  421  575    9 2916  744  336    1  342   14  359 1206   15\n",
      "  334    1  460   26 2742 1070   26  701 4537 1207   21 2173    3   31\n",
      "   10    5 1611    8    6  260    4  702    1  372 1997  912 3946  575\n",
      "    4 1849   17   10  766  810  205   17 1712 2389    1    6   11   21\n",
      "  269 2491]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 100, 50)           3668400   \n",
      "_________________________________________________________________\n",
      "gru_28 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 29)                7453      \n",
      "=================================================================\n",
      "Total params: 3,911,629\n",
      "Trainable params: 3,911,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1189 samples, validate on 397 samples\n",
      "Epoch 1/10\n",
      "1189/1189 [==============================] - 14s 12ms/step - loss: 3.1703 - acc: 0.1110 - val_loss: 2.9645 - val_acc: 0.1436\n",
      "Epoch 2/10\n",
      "1189/1189 [==============================] - 10s 8ms/step - loss: 2.9438 - acc: 0.1203 - val_loss: 2.9023 - val_acc: 0.1436\n",
      "Epoch 3/10\n",
      "1189/1189 [==============================] - 11s 9ms/step - loss: 2.9191 - acc: 0.1203 - val_loss: 2.8696 - val_acc: 0.1436\n",
      "Epoch 4/10\n",
      "1189/1189 [==============================] - 9s 8ms/step - loss: 2.8275 - acc: 0.1203 - val_loss: 2.7532 - val_acc: 0.1436\n",
      "Epoch 5/10\n",
      "1189/1189 [==============================] - 9s 7ms/step - loss: 2.6821 - acc: 0.1236 - val_loss: 2.6478 - val_acc: 0.1486\n",
      "Epoch 6/10\n",
      "1189/1189 [==============================] - 9s 8ms/step - loss: 2.4630 - acc: 0.2052 - val_loss: 2.5460 - val_acc: 0.2191\n",
      "Epoch 7/10\n",
      "1189/1189 [==============================] - 9s 7ms/step - loss: 2.1984 - acc: 0.2994 - val_loss: 2.4771 - val_acc: 0.2645\n",
      "Epoch 8/10\n",
      "1189/1189 [==============================] - 9s 8ms/step - loss: 1.9187 - acc: 0.4062 - val_loss: 2.5554 - val_acc: 0.2544\n",
      "Epoch 9/10\n",
      "1189/1189 [==============================] - 9s 7ms/step - loss: 1.7527 - acc: 0.4844 - val_loss: 2.2708 - val_acc: 0.3300\n",
      "Epoch 10/10\n",
      "1189/1189 [==============================] - 9s 8ms/step - loss: 1.4470 - acc: 0.5416 - val_loss: 2.2337 - val_acc: 0.3451\n",
      "1189/1189 [==============================] - 2s 2ms/step\n",
      "Training Accuracy: 0.6367\n",
      "397/397 [==============================] - 1s 2ms/step\n",
      "Testing Accuracy:  0.3451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17bb8b7ba8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(czechData,29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "12796   danish      1  Forside » Nyheder » H+H øger indtjeninge.. « 1...\n",
      "12797   danish      1  04 sep: Nordea siger farvel til chef for Perso...\n",
      "12798   danish      1  16 aug: WDH/Carnegie: Anbefalingen sænkes til ...\n",
      "12799   danish      1  Forside » Nyheder » Vestas: Igen højere .. « 1...\n",
      "12800   danish      1  23 aug: Ambu fortsætter i vækstsporet og opjus...\n",
      "[ 173    1   54  144    1    5    1    1    9    3    5   71  254 4906\n",
      "   31  907   62   14  421 3149    7   12 1671  983  210    8 1541 1069\n",
      "  304   17 3452 4264   10   15   83   35  500   68  585  440  807   48\n",
      "    3  205  886    1   17    2   14 3286    5    6    3  552 1970    6\n",
      " 1340   25    2   12  719   18    7    3  205  886  254 4906    6    8\n",
      " 2144  807   48 4514    4   18  163 4265   25   24   14    1  104  408\n",
      "    1   17    7  968   10    2   15 4906   16   24 2145    4   10  379\n",
      "  210  205]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, 100, 50)           2267900   \n",
      "_________________________________________________________________\n",
      "gru_31 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 34)                8738      \n",
      "=================================================================\n",
      "Total params: 2,512,414\n",
      "Trainable params: 2,512,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1360 samples, validate on 454 samples\n",
      "Epoch 1/10\n",
      "1360/1360 [==============================] - 10s 7ms/step - loss: 3.2697 - acc: 0.1000 - val_loss: 3.0489 - val_acc: 0.0793\n",
      "Epoch 2/10\n",
      "1360/1360 [==============================] - 8s 6ms/step - loss: 3.0367 - acc: 0.1066 - val_loss: 2.9412 - val_acc: 0.0793\n",
      "Epoch 3/10\n",
      "1360/1360 [==============================] - 7s 5ms/step - loss: 2.8309 - acc: 0.1257 - val_loss: 2.7409 - val_acc: 0.0793\n",
      "Epoch 4/10\n",
      "1360/1360 [==============================] - 7s 5ms/step - loss: 2.5766 - acc: 0.1338 - val_loss: 2.4985 - val_acc: 0.2775\n",
      "Epoch 5/10\n",
      "1360/1360 [==============================] - 7s 5ms/step - loss: 2.2150 - acc: 0.3360 - val_loss: 2.2066 - val_acc: 0.3436\n",
      "Epoch 6/10\n",
      "1360/1360 [==============================] - 7s 5ms/step - loss: 1.8760 - acc: 0.4103 - val_loss: 2.0670 - val_acc: 0.3634\n",
      "Epoch 7/10\n",
      "1360/1360 [==============================] - 7s 5ms/step - loss: 1.6959 - acc: 0.4691 - val_loss: 2.0219 - val_acc: 0.3656\n",
      "Epoch 8/10\n",
      "1360/1360 [==============================] - 7s 6ms/step - loss: 1.6053 - acc: 0.4853 - val_loss: 3.0476 - val_acc: 0.1806\n",
      "Epoch 9/10\n",
      "1360/1360 [==============================] - 7s 5ms/step - loss: 1.8690 - acc: 0.4353 - val_loss: 2.0186 - val_acc: 0.3789\n",
      "Epoch 10/10\n",
      "1360/1360 [==============================] - 8s 6ms/step - loss: 1.4897 - acc: 0.5110 - val_loss: 2.0057 - val_acc: 0.3833\n",
      "1360/1360 [==============================] - 2s 1ms/step\n",
      "Training Accuracy: 0.5397\n",
      "454/454 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.3833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17b9d6fcf8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(danishData,34)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "14610    dutch      1  Dochtertje (4) gooit smartphone vader in zee D...\n",
      "14611    dutch      1  Van der Weijden had een zware nacht, maar zwem...\n",
      "14612    dutch      1  Dit betekent het als je voor de wekker wakker ...\n",
      "14613    dutch      1  In het nieuws Lili en Howick smeken Rutte, Har...\n",
      "14614    dutch      1  Publieke omroep krijgt toch nog extra geld De ...\n",
      "[ 354    5 1765  567    5   12  951  812   13  883  364   14   19   13\n",
      "   23   12  459    4 3763   23 2205  912    7    2    1  197   29    1\n",
      " 2023    2 1992   12    4 1527   47    1 3764  769   89  114  434   22\n",
      "  156 3177    5   51   41    4  154    2   57   12   18 1341 2829   22\n",
      " 1528 3369    5 4637    6  527   34   12  366  173    5    5 1178   12\n",
      "    1 2023    2  223  173    6    1   98    1 2921   24 4430    5 3278\n",
      " 2996    6    3  819    5  500   22 1118  221  223    5 1023   41    1\n",
      " 1765 1403]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, 100, 50)           3234150   \n",
      "_________________________________________________________________\n",
      "gru_33 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 37)                9509      \n",
      "=================================================================\n",
      "Total params: 3,479,435\n",
      "Trainable params: 3,479,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2424 samples, validate on 808 samples\n",
      "Epoch 1/10\n",
      "2424/2424 [==============================] - 17s 7ms/step - loss: 3.4890 - acc: 0.0611 - val_loss: 3.3740 - val_acc: 0.0693\n",
      "Epoch 2/10\n",
      "2424/2424 [==============================] - 14s 6ms/step - loss: 3.2477 - acc: 0.1073 - val_loss: 3.2403 - val_acc: 0.0990\n",
      "Epoch 3/10\n",
      "2424/2424 [==============================] - 14s 6ms/step - loss: 3.0452 - acc: 0.1304 - val_loss: 3.0767 - val_acc: 0.1894\n",
      "Epoch 4/10\n",
      "2424/2424 [==============================] - 14s 6ms/step - loss: 2.7220 - acc: 0.2141 - val_loss: 2.8264 - val_acc: 0.2995\n",
      "Epoch 5/10\n",
      "2424/2424 [==============================] - 14s 6ms/step - loss: 2.3833 - acc: 0.2974 - val_loss: 2.6635 - val_acc: 0.2970\n",
      "Epoch 6/10\n",
      "2424/2424 [==============================] - 14s 6ms/step - loss: 2.0624 - acc: 0.3998 - val_loss: 2.6323 - val_acc: 0.3403\n",
      "Epoch 7/10\n",
      "2424/2424 [==============================] - 15s 6ms/step - loss: 1.7673 - acc: 0.4724 - val_loss: 2.4523 - val_acc: 0.3725\n",
      "Epoch 8/10\n",
      "2424/2424 [==============================] - 14s 6ms/step - loss: 1.4964 - acc: 0.5425 - val_loss: 2.3549 - val_acc: 0.3973\n",
      "Epoch 9/10\n",
      "2424/2424 [==============================] - 14s 6ms/step - loss: 1.3230 - acc: 0.6019 - val_loss: 2.3620 - val_acc: 0.4158\n",
      "Epoch 10/10\n",
      "2424/2424 [==============================] - 15s 6ms/step - loss: 1.1357 - acc: 0.6564 - val_loss: 2.4173 - val_acc: 0.4121\n",
      "2424/2424 [==============================] - 3s 1ms/step\n",
      "Training Accuracy: 0.7244\n",
      "808/808 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.4121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17c9938160>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(dutchData,37)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "24042   german      1  14.08.2018 - 14:19 Ein Ass auf dem Basketballp...\n",
      "24043   german      1  14.08.2018 - 12:40 Kollaboration der Superlati...\n",
      "24044   german      1  13.08.2018 - 15:49 Unglaublicher WeltrekordAll...\n",
      "24045   german      1  FacebookHachenburg (ots) – Am Montagabend, 20....\n",
      "24046   german      1  FacebookPfalzfeld (ots) – Am frühen Dienstagmo...\n",
      "[1927  154 1439  271 1624    1  287    1   30   41 1625   25 2521   59\n",
      "    1   90  395   20   12 2571  764    4  134   59 3132   95  108   60\n",
      "   80  484   64  795 1345    3 2133   34    5  598   27   28   46  264\n",
      " 3049   27   36    4    9  396  104   98    7   41 2037 1991   25 3417\n",
      " 1255   13  421 1538  271 1624   52  178    1 3132   18   59    1  349\n",
      " 2852    1  224 1957   38 1440 4785    2  555   37  337    3    3  514\n",
      "   15   12    1 3219    3 3778    3   22 2134    2    1    3   13 2522\n",
      "   14 3418]\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_39 (Embedding)     (None, 100, 50)           4955900   \n",
      "_________________________________________________________________\n",
      "gru_41 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 44)                11308     \n",
      "=================================================================\n",
      "Total params: 5,202,984\n",
      "Trainable params: 5,202,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 23s 8ms/step - loss: 3.7020 - acc: 0.0490 - val_loss: 3.6276 - val_acc: 0.0550\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 21s 7ms/step - loss: 3.5961 - acc: 0.0710 - val_loss: 3.5892 - val_acc: 0.0890\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 20s 7ms/step - loss: 3.4522 - acc: 0.0953 - val_loss: 3.5121 - val_acc: 0.0800\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 21s 7ms/step - loss: 3.2916 - acc: 0.0987 - val_loss: 3.4587 - val_acc: 0.0930\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 21s 7ms/step - loss: 3.0937 - acc: 0.1563 - val_loss: 3.3901 - val_acc: 0.1260\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 21s 7ms/step - loss: 2.8205 - acc: 0.2313 - val_loss: 3.3445 - val_acc: 0.1720\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 20s 7ms/step - loss: 2.4833 - acc: 0.3200 - val_loss: 3.2186 - val_acc: 0.2050\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 21s 7ms/step - loss: 2.1494 - acc: 0.4063 - val_loss: 3.2640 - val_acc: 0.2150\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 21s 7ms/step - loss: 1.8505 - acc: 0.4797 - val_loss: 3.2761 - val_acc: 0.2310\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 21s 7ms/step - loss: 1.6074 - acc: 0.5570 - val_loss: 3.3462 - val_acc: 0.2490\n",
      "3000/3000 [==============================] - 4s 1ms/step\n",
      "Training Accuracy: 0.6513\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.2490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17b186cba8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(germanData,44)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "28042    greek      1  Χάος στην Σουηδία από οργανωμένες επιθέσεις κα...\n",
      "28043    greek      1  Καταρρέει η τουρκική λίρα… 30/08/2018, 10:22 Μ...\n",
      "28044    greek      1  Θεσσαλονίκη: Διαμαρτυρία για τους πλειστηριασμ...\n",
      "28045    greek      1  Ξεσήκωσε το νησί γνωστό μοντέλο με στρινγκ μαγ...\n",
      "28046    greek      1  Search for: Search Χρησιμοποιούμε cookies για ...\n",
      "[   6    5  364    3  543   23  544   22  101 3736   21  576    3   19\n",
      "  555    3  543   12   29  798 2639  583    8    6 4279   65   13 1644\n",
      " 1698   20  987   12   84   16    2  212   11   16  647   42   10   20\n",
      "  543  353   96    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_41 (Embedding)     (None, 100, 50)           3217150   \n",
      "_________________________________________________________________\n",
      "gru_43 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 29)                7453      \n",
      "=================================================================\n",
      "Total params: 3,460,379\n",
      "Trainable params: 3,460,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1752 samples, validate on 584 samples\n",
      "Epoch 1/10\n",
      "1752/1752 [==============================] - 13s 7ms/step - loss: 3.2362 - acc: 0.0885 - val_loss: 3.0983 - val_acc: 0.0788\n",
      "Epoch 2/10\n",
      "1752/1752 [==============================] - 10s 6ms/step - loss: 2.9997 - acc: 0.0959 - val_loss: 2.9644 - val_acc: 0.0873\n",
      "Epoch 3/10\n",
      "1752/1752 [==============================] - 10s 6ms/step - loss: 2.8998 - acc: 0.1096 - val_loss: 2.8787 - val_acc: 0.1216\n",
      "Epoch 4/10\n",
      "1752/1752 [==============================] - 10s 6ms/step - loss: 2.7487 - acc: 0.1313 - val_loss: 2.7894 - val_acc: 0.1301\n",
      "Epoch 5/10\n",
      "1752/1752 [==============================] - 11s 6ms/step - loss: 2.5610 - acc: 0.1775 - val_loss: 2.6751 - val_acc: 0.1644\n",
      "Epoch 6/10\n",
      "1752/1752 [==============================] - 10s 6ms/step - loss: 2.3118 - acc: 0.2517 - val_loss: 2.5669 - val_acc: 0.2483\n",
      "Epoch 7/10\n",
      "1752/1752 [==============================] - 11s 6ms/step - loss: 2.0687 - acc: 0.3413 - val_loss: 2.5298 - val_acc: 0.2997\n",
      "Epoch 8/10\n",
      "1752/1752 [==============================] - 11s 6ms/step - loss: 1.8168 - acc: 0.4275 - val_loss: 2.3817 - val_acc: 0.3219\n",
      "Epoch 9/10\n",
      "1752/1752 [==============================] - 11s 6ms/step - loss: 1.5551 - acc: 0.5211 - val_loss: 2.3152 - val_acc: 0.3339\n",
      "Epoch 10/10\n",
      "1752/1752 [==============================] - 11s 6ms/step - loss: 1.3165 - acc: 0.5788 - val_loss: 2.3452 - val_acc: 0.3442\n",
      "1752/1752 [==============================] - 2s 1ms/step\n",
      "Training Accuracy: 0.6279\n",
      "584/584 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.3442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17ba0595c0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(greekData,29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "30378   hebrew     12  עידו שחם • 18 באוגוסט 2018 איתי איתי זבולון או...\n",
      "30379   hebrew     12  עידו שחם • 20 באוגוסט 2018שעה באולפן עם להקת ה...\n",
      "30380   hebrew     12  Home / DIY VIDEOS / עשה/י זאת בעצמך: DIY מחברו...\n",
      "30381   hebrew     12  עידו שחם • 18 245: מלאכותישעה של מוזיקה אקלקטי...\n",
      "30382   hebrew     12  ניצן אגסי • 1 בספטמבר 2018 איה זהבי פייגלין בר...\n",
      "[ 189  436  893    1   29 4296 1354    3 3927 1355    1  593   29 3083\n",
      "  593    7  182 1674 1921 4741 3339 1191   22   94 1192  114 2233 1040\n",
      "  243  616 1356 2234  129   27   76    1 3084   60    1 3928    7 1476\n",
      " 1309  527 1041 3925   21 2865    2  167   29  540 1042 2233   21 3340\n",
      "  894 1191  743 2020 2866 3620    1 2698  238  801    5 2867 4297 2699\n",
      "    1   38 2233 1040  243  616  377  357   29 4742  109  895   11 2021\n",
      "    2  295   88  767    9  205    1 1078 1477   26   32  403  728 3929\n",
      "   94  197]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_43 (Embedding)     (None, 100, 50)           2633850   \n",
      "_________________________________________________________________\n",
      "gru_45 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 17)                4369      \n",
      "=================================================================\n",
      "Total params: 2,873,995\n",
      "Trainable params: 2,873,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 771 samples, validate on 258 samples\n",
      "Epoch 1/10\n",
      "771/771 [==============================] - 8s 10ms/step - loss: 2.6809 - acc: 0.1855 - val_loss: 2.3681 - val_acc: 0.0736\n",
      "Epoch 2/10\n",
      "771/771 [==============================] - 4s 6ms/step - loss: 2.3317 - acc: 0.1933 - val_loss: 2.3112 - val_acc: 0.1667\n",
      "Epoch 3/10\n",
      "771/771 [==============================] - 4s 6ms/step - loss: 2.2358 - acc: 0.2153 - val_loss: 2.1227 - val_acc: 0.2791\n",
      "Epoch 4/10\n",
      "771/771 [==============================] - 4s 6ms/step - loss: 2.0044 - acc: 0.2672 - val_loss: 1.9885 - val_acc: 0.1977\n",
      "Epoch 5/10\n",
      "771/771 [==============================] - 4s 6ms/step - loss: 1.8646 - acc: 0.2516 - val_loss: 1.9436 - val_acc: 0.2326\n",
      "Epoch 6/10\n",
      "771/771 [==============================] - 4s 6ms/step - loss: 1.8848 - acc: 0.2438 - val_loss: 1.9499 - val_acc: 0.2442\n",
      "Epoch 7/10\n",
      "771/771 [==============================] - 4s 6ms/step - loss: 1.7482 - acc: 0.3074 - val_loss: 1.8591 - val_acc: 0.3023\n",
      "Epoch 8/10\n",
      "771/771 [==============================] - 5s 6ms/step - loss: 1.6169 - acc: 0.3515 - val_loss: 1.7813 - val_acc: 0.3178\n",
      "Epoch 9/10\n",
      "771/771 [==============================] - 4s 6ms/step - loss: 1.4217 - acc: 0.4060 - val_loss: 1.7486 - val_acc: 0.4070\n",
      "Epoch 10/10\n",
      "771/771 [==============================] - 5s 6ms/step - loss: 1.2421 - acc: 0.4643 - val_loss: 1.7136 - val_acc: 0.4302\n",
      "771/771 [==============================] - 1s 1ms/step\n",
      "Training Accuracy: 0.5084\n",
      "258/258 [==============================] - 0s 1ms/step\n",
      "Testing Accuracy:  0.4302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17b813b860>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(hebrewData,17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "34286  italian      1  agosto 16, 2018 Gli informati SCONTI-COUPON 0C...\n",
      "34287  italian      1  agosto 27, 2018 Gli informati SCONTI-COUPON 0C...\n",
      "34288  italian      1  settembre 3, 2018 Gli informati SCONTI-COUPON ...\n",
      "34289  italian      1  settembre 7, 2018 Gli informati SCONTI-COUPON ...\n",
      "34290  italian      1   SCONTI-COUPON 0Prova a vincere un Samsung Gal...\n",
      "[   8   48  336   12  430   40   18   10  470    7  287   14  134    1\n",
      "  386 3840    2   16   58   19 1290   13    4    1   20  100 4195    1\n",
      "  121  232    3 2162  485 1395   37    6   19   13    1    4   29 2874\n",
      "    1    9 1228 2340    6    6  683   19   57    3  485   19 2757   12\n",
      "    6 1201    6    2   39  143   68 1641 4729 3559    7   16  855    1\n",
      "  830   10   14  946    1 3841  385  188    2    1   86   10 1092   19\n",
      "  305  132    1 3842   20 1597    1  810    2 3648    2   12 3054    8\n",
      "    3 1228]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_53 (Embedding)     (None, 100, 50)           3916800   \n",
      "_________________________________________________________________\n",
      "gru_55 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 40)                10280     \n",
      "=================================================================\n",
      "Total params: 4,162,856\n",
      "Trainable params: 4,162,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2789 samples, validate on 930 samples\n",
      "Epoch 1/10\n",
      "2789/2789 [==============================] - 21s 8ms/step - loss: 3.5833 - acc: 0.0749 - val_loss: 3.4841 - val_acc: 0.0785\n",
      "Epoch 2/10\n",
      "2789/2789 [==============================] - 19s 7ms/step - loss: 3.3680 - acc: 0.0939 - val_loss: 3.3584 - val_acc: 0.0839\n",
      "Epoch 3/10\n",
      "2789/2789 [==============================] - 23s 8ms/step - loss: 3.1769 - acc: 0.1119 - val_loss: 3.2212 - val_acc: 0.1129\n",
      "Epoch 4/10\n",
      "2789/2789 [==============================] - 17s 6ms/step - loss: 2.9129 - acc: 0.1535 - val_loss: 3.0590 - val_acc: 0.1527\n",
      "Epoch 5/10\n",
      "2789/2789 [==============================] - 21s 7ms/step - loss: 2.6448 - acc: 0.2101 - val_loss: 2.9415 - val_acc: 0.2000\n",
      "Epoch 6/10\n",
      "2789/2789 [==============================] - 17s 6ms/step - loss: 2.4011 - acc: 0.2829 - val_loss: 3.1885 - val_acc: 0.1495\n",
      "Epoch 7/10\n",
      "2789/2789 [==============================] - 17s 6ms/step - loss: 2.9864 - acc: 0.2392 - val_loss: 3.0545 - val_acc: 0.2194\n",
      "Epoch 8/10\n",
      "2789/2789 [==============================] - 17s 6ms/step - loss: 2.3337 - acc: 0.3327 - val_loss: 2.8782 - val_acc: 0.2828\n",
      "Epoch 9/10\n",
      "2789/2789 [==============================] - 17s 6ms/step - loss: 1.9928 - acc: 0.4281 - val_loss: 2.8913 - val_acc: 0.3151\n",
      "Epoch 10/10\n",
      "2789/2789 [==============================] - 17s 6ms/step - loss: 1.7756 - acc: 0.4855 - val_loss: 2.8513 - val_acc: 0.3333\n",
      "2789/2789 [==============================] - 3s 1ms/step\n",
      "Training Accuracy: 0.5712\n",
      "930/930 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17a33f3c18>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(italianData,40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "40647   korean     12  - 오늘 다녀간 맛집을 기록하고, 추억을 보관하세요.- 가보고 싶은 맛집을 기록해두...\n",
      "40648   korean     12  Ai-Pay 에서는 2가지 서비스를 제공 하고 있습니다.1. 쇼핑몰 연동형 결제 모...\n",
      "40649   korean     12  따뜻한 마음을 담고 나눌 캐릭터의 힘, 캐릭터 마케팅 벌이는 이랜드의 새 캐릭터 러...\n",
      "40650   korean     12  Home / DIY VIDEOS / DIY 여성 2 layer pleats band...\n",
      "40651   korean     12  아마존 파이어 HD 8(Amazon Fire HD)... 아마존 알렉사 핸즈 프리를...\n",
      "[ 112  608  377   85 3146 3147 4751  224 1226 4752 1663 1128 3142   57\n",
      "  224  392 3146  105  482   57  224  296   44   78  250 2659   57  224\n",
      "   57  697   20  623 1047   28   50  361  623 1047 3783  500   28   52\n",
      "  296 3148   52  296   28   52  296   28   52  296   54   47  500   28\n",
      "   50  361 4202   54  657  347    2  212   57  482   57   20  105   63\n",
      "   57   85 1664   57 1173   85 2492   57  560  643 1284 4753 1752  105\n",
      " 3400   85 1661 1012 3144  224  392 1285 1752  224  392 1285 1752 4203\n",
      " 4754 2660]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_55 (Embedding)     (None, 100, 50)           3107300   \n",
      "_________________________________________________________________\n",
      "gru_57 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 21)                5397      \n",
      "=================================================================\n",
      "Total params: 3,348,473\n",
      "Trainable params: 3,348,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 870 samples, validate on 291 samples\n",
      "Epoch 1/10\n",
      "870/870 [==============================] - 9s 11ms/step - loss: 2.8419 - acc: 0.1586 - val_loss: 2.6169 - val_acc: 0.1512\n",
      "Epoch 2/10\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 2.6397 - acc: 0.1655 - val_loss: 2.6286 - val_acc: 0.1512\n",
      "Epoch 3/10\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 2.6017 - acc: 0.1655 - val_loss: 2.5944 - val_acc: 0.1512\n",
      "Epoch 4/10\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 2.5248 - acc: 0.1655 - val_loss: 2.4880 - val_acc: 0.1512\n",
      "Epoch 5/10\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 2.3863 - acc: 0.1701 - val_loss: 2.4361 - val_acc: 0.2131\n",
      "Epoch 6/10\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 2.1768 - acc: 0.2333 - val_loss: 2.2050 - val_acc: 0.2027\n",
      "Epoch 7/10\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 2.0629 - acc: 0.2218 - val_loss: 2.0990 - val_acc: 0.2268\n",
      "Epoch 8/10\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 1.9350 - acc: 0.2126 - val_loss: 1.9567 - val_acc: 0.2337\n",
      "Epoch 9/10\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 1.7347 - acc: 0.3402 - val_loss: 1.7730 - val_acc: 0.3299\n",
      "Epoch 10/10\n",
      "870/870 [==============================] - 5s 6ms/step - loss: 1.5037 - acc: 0.4782 - val_loss: 1.5930 - val_acc: 0.3849\n",
      "870/870 [==============================] - 1s 1ms/step\n",
      "Training Accuracy: 0.5092\n",
      "291/291 [==============================] - 0s 1ms/step\n",
      "Testing Accuracy:  0.3849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17a8be9e80>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(koreanData,21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "43077   polish      1  17 lutego 2011, na swoim blogu na portalu Salo...\n",
      "43078   polish      1  – serwis gwarancyjny i pogwarancyjny PARAMETRY...\n",
      "43079   polish      1  relacje społeczneJako że jednym z założeń, któ...\n",
      "43080   polish      1  Huna w Starym Testamencie, Materiały Zebrane, ...\n",
      "43081   polish      1  Twittericon Masz konto na Twitterze? Zacznij n...\n",
      "[4714   94 3618   77   22    3   52 3255    5   15    1 3845 3255    5\n",
      "  545   15    1 3845  236    1  165 3107  161   88    3 1353  236    3\n",
      " 1498    7  574    8  507   25  165  942    1  508  454  314  501    3\n",
      "   33 2943   32  278   33   12 1105 1200 1454    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_61 (Embedding)     (None, 100, 50)           3458700   \n",
      "_________________________________________________________________\n",
      "gru_63 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 32)                8224      \n",
      "=================================================================\n",
      "Total params: 3,702,700\n",
      "Trainable params: 3,702,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1632 samples, validate on 545 samples\n",
      "Epoch 1/10\n",
      "1632/1632 [==============================] - 16s 10ms/step - loss: 3.2939 - acc: 0.0729 - val_loss: 3.1632 - val_acc: 0.0862\n",
      "Epoch 2/10\n",
      "1632/1632 [==============================] - 10s 6ms/step - loss: 3.0880 - acc: 0.0888 - val_loss: 3.0282 - val_acc: 0.0734\n",
      "Epoch 3/10\n",
      "1632/1632 [==============================] - 9s 6ms/step - loss: 2.9825 - acc: 0.0950 - val_loss: 2.9631 - val_acc: 0.0826\n",
      "Epoch 4/10\n",
      "1632/1632 [==============================] - 9s 6ms/step - loss: 2.8288 - acc: 0.0993 - val_loss: 2.8727 - val_acc: 0.0917\n",
      "Epoch 5/10\n",
      "1632/1632 [==============================] - 11s 7ms/step - loss: 2.6621 - acc: 0.1146 - val_loss: 2.8307 - val_acc: 0.1046\n",
      "Epoch 6/10\n",
      "1632/1632 [==============================] - 10s 6ms/step - loss: 2.5228 - acc: 0.1275 - val_loss: 2.8662 - val_acc: 0.1138\n",
      "Epoch 7/10\n",
      "1632/1632 [==============================] - 10s 6ms/step - loss: 2.2904 - acc: 0.2267 - val_loss: 2.6846 - val_acc: 0.1853\n",
      "Epoch 8/10\n",
      "1632/1632 [==============================] - 10s 6ms/step - loss: 2.0452 - acc: 0.3352 - val_loss: 2.5507 - val_acc: 0.2422\n",
      "Epoch 9/10\n",
      "1632/1632 [==============================] - 10s 6ms/step - loss: 1.7254 - acc: 0.4252 - val_loss: 2.4112 - val_acc: 0.2844\n",
      "Epoch 10/10\n",
      "1632/1632 [==============================] - 10s 6ms/step - loss: 1.4778 - acc: 0.4969 - val_loss: 2.3863 - val_acc: 0.2936\n",
      "1632/1632 [==============================] - 2s 1ms/step\n",
      "Training Accuracy: 0.5748\n",
      "545/545 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.2936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17aac61cc0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(polishData,32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Language  Label                                               Text\n",
      "48630  romanian      1  TweetEla Crăciun, prezentatoare TV și autoarea...\n",
      "48631  romanian      1  N-am mai scris de mult timp un articol dedicat...\n",
      "48632  romanian      1  Am urmarit ca de obicei evenimentele din Piata...\n",
      "48633  romanian     12  14 august 2018am și eu o întrebare… ăstora cin...\n",
      "48634  romanian     12   Melania Trump, Donald Trump, Autor Gabriela B...\n",
      "[ 812   32   29  925    4 1037 1165  100 1541    3  204  820   22    8\n",
      "    6   36 3815    3  129  110    2 1165    2  216 4593 2822    4    7\n",
      " 2269 2407 2106    1 1132   16   32   29  658    7    1  812   61   24\n",
      " 2001    2 1606   21 1480    1    2   63  658   14 1664   33 2823   15\n",
      "  658    7 1481    1 3816 1807    2  608    3  743  742   10 2106    1\n",
      " 1132   16   10   32 1249 1430    1 1082    1  431  291   10    5   24\n",
      "   32   29 1291  455   42  620   17   32    4  244 1133    1  223   38\n",
      "  570  143]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_69 (Embedding)     (None, 100, 50)           3233950   \n",
      "_________________________________________________________________\n",
      "gru_71 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 29)                7453      \n",
      "=================================================================\n",
      "Total params: 3,477,179\n",
      "Trainable params: 3,477,179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1800 samples, validate on 600 samples\n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 15s 8ms/step - loss: 3.2880 - acc: 0.0956 - val_loss: 3.1986 - val_acc: 0.0867\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 11s 6ms/step - loss: 3.1020 - acc: 0.0983 - val_loss: 3.0616 - val_acc: 0.1333\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 11s 6ms/step - loss: 2.8947 - acc: 0.1683 - val_loss: 2.8900 - val_acc: 0.1683\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 11s 6ms/step - loss: 2.5359 - acc: 0.2083 - val_loss: 2.6019 - val_acc: 0.1917\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 11s 6ms/step - loss: 2.1116 - acc: 0.3456 - val_loss: 2.3853 - val_acc: 0.2850\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 11s 6ms/step - loss: 1.7561 - acc: 0.4594 - val_loss: 2.2878 - val_acc: 0.3400\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 11s 6ms/step - loss: 1.4963 - acc: 0.5317 - val_loss: 2.2264 - val_acc: 0.3750\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 11s 6ms/step - loss: 1.2720 - acc: 0.5878 - val_loss: 2.2410 - val_acc: 0.3733\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 11s 6ms/step - loss: 1.1003 - acc: 0.6311 - val_loss: 2.1844 - val_acc: 0.4117\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 11s 6ms/step - loss: 1.0411 - acc: 0.6417 - val_loss: 2.2560 - val_acc: 0.4017\n",
      "1800/1800 [==============================] - 2s 1ms/step\n",
      "Training Accuracy: 0.6944\n",
      "600/600 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.4017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f1799d64630>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(romanianData,29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "51030  russian      1  Складская программа и продажи на Amazon ; Прод...\n",
      "51031  russian      1  Сколько стоит простой сайт? 11 сентября 2018 Б...\n",
      "51032  russian      1  20 Августа 2018 в 15:06 228 Новостные медиа и ...\n",
      "51033  russian      1  Дарья Кармадонова 24.08.2018 в 15:00 О роли ин...\n",
      "51034  russian      1  Четвёртый SEO-марафон от 9SEO . Для тех, кто н...\n",
      "[3051    3 4019 4020 1486  486 4783   65   55   14   73 4240   16   11\n",
      " 3051 1486  183 3474  307  121   27   41   90 1875    2  699    3  101\n",
      "  288 3301   96  193 4508  867  398  292  794    3  220  250  673 1523\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_71 (Embedding)     (None, 100, 50)           4735600   \n",
      "_________________________________________________________________\n",
      "gru_73 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 33)                8481      \n",
      "=================================================================\n",
      "Total params: 4,979,857\n",
      "Trainable params: 4,979,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1983 samples, validate on 661 samples\n",
      "Epoch 1/10\n",
      "1983/1983 [==============================] - 18s 9ms/step - loss: 3.3195 - acc: 0.0943 - val_loss: 3.2007 - val_acc: 0.1241\n",
      "Epoch 2/10\n",
      "1983/1983 [==============================] - 13s 6ms/step - loss: 3.0793 - acc: 0.1251 - val_loss: 3.1219 - val_acc: 0.1316\n",
      "Epoch 3/10\n",
      "1983/1983 [==============================] - 12s 6ms/step - loss: 2.9408 - acc: 0.1417 - val_loss: 3.0076 - val_acc: 0.1165\n",
      "Epoch 4/10\n",
      "1983/1983 [==============================] - 13s 6ms/step - loss: 2.7874 - acc: 0.1397 - val_loss: 2.8847 - val_acc: 0.1573\n",
      "Epoch 5/10\n",
      "1983/1983 [==============================] - 13s 6ms/step - loss: 2.5080 - acc: 0.1957 - val_loss: 2.7364 - val_acc: 0.2133\n",
      "Epoch 6/10\n",
      "1983/1983 [==============================] - 13s 6ms/step - loss: 2.2247 - acc: 0.2824 - val_loss: 2.6063 - val_acc: 0.2330\n",
      "Epoch 7/10\n",
      "1983/1983 [==============================] - 13s 7ms/step - loss: 1.9860 - acc: 0.3646 - val_loss: 2.4880 - val_acc: 0.2980\n",
      "Epoch 8/10\n",
      "1983/1983 [==============================] - 13s 7ms/step - loss: 1.7134 - acc: 0.4766 - val_loss: 2.4421 - val_acc: 0.3071\n",
      "Epoch 9/10\n",
      "1983/1983 [==============================] - 13s 6ms/step - loss: 1.5198 - acc: 0.5093 - val_loss: 2.4727 - val_acc: 0.3147\n",
      "Epoch 10/10\n",
      "1983/1983 [==============================] - 13s 7ms/step - loss: 1.3385 - acc: 0.5527 - val_loss: 2.5187 - val_acc: 0.3404\n",
      "1983/1983 [==============================] - 2s 1ms/step\n",
      "Training Accuracy: 0.5940\n",
      "661/661 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.3404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f1793843cf8>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(russianData,33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "53674  serbian      1  Prokupački budžet – za vlast u suficitu, za op...\n",
      "53675  serbian      1  Međunarodna izložba pasa u Leskovcu by Admin /...\n",
      "53676  serbian      1  Železničar ispao iz EHF kupa, Kaerjeng prejak ...\n",
      "53677  serbian      1  Odbornici većine u Blacu: Iza hapšenja predsed...\n",
      "53678  serbian      1  Promene na čelu svrljiške Skupštine VestiNakon...\n",
      "[  43  145  490   16    6  317   31  374 1056   23   66  594   91    6\n",
      "    2    1 1205  425    3 3173  474    1    5  979 1057 3174   58 1613\n",
      "   73  124   88    5  223    3   11 2081   43  323 3581    2   81 1377\n",
      "    1  474  770 1704   43  491  827    5 3582   69  124 3583  420    9\n",
      " 2231 1205  859    1   33    3    2  671 3584 3585    8 1818   66    8\n",
      "   83 4661  474   20  113  337    3 1058  247   58    4   38   83  120\n",
      "  712 3586   14    1  884    5  389   73  944   71  131  167 1705   58\n",
      "   43  145]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_73 (Embedding)     (None, 100, 50)           2378200   \n",
      "_________________________________________________________________\n",
      "gru_75 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 2,619,116\n",
      "Trainable params: 2,619,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 951 samples, validate on 318 samples\n",
      "Epoch 1/10\n",
      "951/951 [==============================] - 11s 11ms/step - loss: 2.8736 - acc: 0.1767 - val_loss: 2.6912 - val_acc: 0.1164\n",
      "Epoch 2/10\n",
      "951/951 [==============================] - 7s 7ms/step - loss: 2.6170 - acc: 0.1872 - val_loss: 2.6668 - val_acc: 0.1258\n",
      "Epoch 3/10\n",
      "951/951 [==============================] - 6s 6ms/step - loss: 2.5045 - acc: 0.2082 - val_loss: 2.5098 - val_acc: 0.1289\n",
      "Epoch 4/10\n",
      "951/951 [==============================] - 7s 7ms/step - loss: 2.3955 - acc: 0.2082 - val_loss: 2.4784 - val_acc: 0.1321\n",
      "Epoch 5/10\n",
      "951/951 [==============================] - 5s 6ms/step - loss: 2.2303 - acc: 0.2093 - val_loss: 2.3292 - val_acc: 0.1478\n",
      "Epoch 6/10\n",
      "951/951 [==============================] - 5s 5ms/step - loss: 1.9825 - acc: 0.2629 - val_loss: 2.2068 - val_acc: 0.2327\n",
      "Epoch 7/10\n",
      "951/951 [==============================] - 5s 5ms/step - loss: 1.6827 - acc: 0.3438 - val_loss: 2.0164 - val_acc: 0.2547\n",
      "Epoch 8/10\n",
      "951/951 [==============================] - 5s 5ms/step - loss: 1.4232 - acc: 0.4364 - val_loss: 1.9575 - val_acc: 0.3082\n",
      "Epoch 9/10\n",
      "951/951 [==============================] - 5s 5ms/step - loss: 1.3171 - acc: 0.4543 - val_loss: 1.8731 - val_acc: 0.2736\n",
      "Epoch 10/10\n",
      "951/951 [==============================] - 5s 5ms/step - loss: 1.2027 - acc: 0.5037 - val_loss: 1.8825 - val_acc: 0.3522\n",
      "951/951 [==============================] - 1s 1ms/step\n",
      "Training Accuracy: 0.5510\n",
      "318/318 [==============================] - 0s 1ms/step\n",
      "Testing Accuracy:  0.3522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17b2194550>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(serbianData,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Language  Label                                               Text\n",
      "54943  slovenian     12  Slovenka iz Züricha: zakaj švicarsko zdravstvo...\n",
      "54944  slovenian     12  Kako se pravilno lotiti nakupovanja šolskih po...\n",
      "54945  slovenian     12  Otroci morajo biti popoldne doma, da se umirij...\n",
      "54946  slovenian     12  Potrebujete popolno preobrazbo? Vsebino omogoč...\n",
      "54947  slovenian     12  Kdo je kriv, da je sodišče moralo odmrzniti pr...\n",
      "[2755    1    4 3806 2756   11 1256    4  417 4332  104    6 1405 1845\n",
      "  512    1  278  304    4  563   11 3807 4333 4987   55  222    5   21\n",
      " 3808 3805 1201   24   61  912 1406    4  479 2516 1734 3365 4334   11\n",
      " 4986    2   31   10    4 2516  133 4987   28 1614 3808 3805    9    6\n",
      " 1846    3  382 2755    8    1 1847   43  417 4332  104    3 1844   13\n",
      "   36 3809   63  953  954 3810    6 1405 4335  104 1848  119  238   28\n",
      "   30   91  218 4988  499  337    5  486  183  471    5   13  343  376\n",
      "   72  480]\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_75 (Embedding)     (None, 100, 50)           1546200   \n",
      "_________________________________________________________________\n",
      "gru_77 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 15)                3855      \n",
      "=================================================================\n",
      "Total params: 1,785,831\n",
      "Trainable params: 1,785,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 485 samples, validate on 162 samples\n",
      "Epoch 1/10\n",
      "485/485 [==============================] - 8s 17ms/step - loss: 2.6084 - acc: 0.2845 - val_loss: 2.1857 - val_acc: 0.3210\n",
      "Epoch 2/10\n",
      "485/485 [==============================] - 3s 5ms/step - loss: 2.1848 - acc: 0.3052 - val_loss: 2.0759 - val_acc: 0.3210\n",
      "Epoch 3/10\n",
      "485/485 [==============================] - 3s 5ms/step - loss: 2.1039 - acc: 0.3052 - val_loss: 2.0280 - val_acc: 0.3210\n",
      "Epoch 4/10\n",
      "485/485 [==============================] - 3s 5ms/step - loss: 1.9898 - acc: 0.3052 - val_loss: 1.8809 - val_acc: 0.3210\n",
      "Epoch 5/10\n",
      "485/485 [==============================] - 3s 5ms/step - loss: 1.8083 - acc: 0.3052 - val_loss: 1.8046 - val_acc: 0.3148\n",
      "Epoch 6/10\n",
      "485/485 [==============================] - 3s 5ms/step - loss: 1.7095 - acc: 0.2969 - val_loss: 1.6950 - val_acc: 0.3210\n",
      "Epoch 7/10\n",
      "485/485 [==============================] - 3s 5ms/step - loss: 1.5497 - acc: 0.3546 - val_loss: 1.6144 - val_acc: 0.3457\n",
      "Epoch 8/10\n",
      "485/485 [==============================] - 3s 6ms/step - loss: 1.3400 - acc: 0.3670 - val_loss: 2.1515 - val_acc: 0.4012\n",
      "Epoch 9/10\n",
      "485/485 [==============================] - 3s 5ms/step - loss: 1.3498 - acc: 0.4845 - val_loss: 1.5388 - val_acc: 0.4012\n",
      "Epoch 10/10\n",
      "485/485 [==============================] - 3s 5ms/step - loss: 1.1901 - acc: 0.4021 - val_loss: 1.4789 - val_acc: 0.4383\n",
      "485/485 [==============================] - 1s 1ms/step\n",
      "Training Accuracy: 0.4598\n",
      "162/162 [==============================] - 0s 2ms/step\n",
      "Testing Accuracy:  0.4383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f17b21808d0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(slovenianData,15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "61964  turkish      1  Bebeğinizin İsmini Harland Koyar Mıydınız? KFC...\n",
      "61965  turkish      1  4Kahve lekesiyle tamamlanan kartpostallar , bu...\n",
      "61966  turkish      1  Cannes Lions Gürsu’nun Elektrik Trafo Dolaplar...\n",
      "61967  turkish      1  Cannes Lions Chef’s Table’da Bir Türk Şef: Mus...\n",
      "61968  turkish      1  Beren Saat Greenpeace için orangutanların sesi...\n",
      "[   1   54  962   25 4442  775    1 1892  650 1546  319  128   34  120\n",
      " 3930    1  650 3720  650 1732 3931  157   11   21    1 3720  146 2515\n",
      "  213    3 2516 3354  194   14 1893 3052  623 2801  930 3194 3053   38\n",
      "    2 1733 3932  120 4181   37   55   78    2 1840   21  239  531    3\n",
      " 1432 3933 2422 3934 2193  291    2  194  173 3930 1894  141 1547  360\n",
      "   83  180 1548 2066 4182 3195 1734 2802 1895 2354 4183   47  118 2194\n",
      " 1200   65 2133  175  762    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_80 (Embedding)     (None, 100, 50)           3960550   \n",
      "_________________________________________________________________\n",
      "gru_82 (GRU)                 (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 31)                7967      \n",
      "=================================================================\n",
      "Total params: 4,204,293\n",
      "Trainable params: 4,204,293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1607 samples, validate on 536 samples\n",
      "Epoch 1/10\n",
      "1607/1607 [==============================] - 16s 10ms/step - loss: 3.2723 - acc: 0.0778 - val_loss: 3.1598 - val_acc: 0.1063\n",
      "Epoch 2/10\n",
      "1607/1607 [==============================] - 11s 7ms/step - loss: 3.1020 - acc: 0.0946 - val_loss: 3.1057 - val_acc: 0.1063\n",
      "Epoch 3/10\n",
      "1607/1607 [==============================] - 11s 7ms/step - loss: 2.9565 - acc: 0.1450 - val_loss: 3.0428 - val_acc: 0.1530\n",
      "Epoch 4/10\n",
      "1607/1607 [==============================] - 11s 7ms/step - loss: 2.7785 - acc: 0.2296 - val_loss: 2.8038 - val_acc: 0.2201\n",
      "Epoch 5/10\n",
      "1607/1607 [==============================] - 11s 7ms/step - loss: 2.5197 - acc: 0.2999 - val_loss: 2.6302 - val_acc: 0.2519\n",
      "Epoch 6/10\n",
      "1607/1607 [==============================] - 11s 7ms/step - loss: 2.2693 - acc: 0.3385 - val_loss: 2.6195 - val_acc: 0.2631\n",
      "Epoch 7/10\n",
      "1607/1607 [==============================] - 12s 7ms/step - loss: 2.0789 - acc: 0.3989 - val_loss: 2.5137 - val_acc: 0.3228\n",
      "Epoch 8/10\n",
      "1607/1607 [==============================] - 12s 7ms/step - loss: 1.9036 - acc: 0.4549 - val_loss: 2.4375 - val_acc: 0.3265\n",
      "Epoch 9/10\n",
      "1607/1607 [==============================] - 11s 7ms/step - loss: 1.6802 - acc: 0.5177 - val_loss: 2.4603 - val_acc: 0.2892\n",
      "Epoch 10/10\n",
      "1607/1607 [==============================] - 11s 7ms/step - loss: 1.5351 - acc: 0.5358 - val_loss: 2.4516 - val_acc: 0.3172\n",
      "1607/1607 [==============================] - 2s 1ms/step\n",
      "Training Accuracy: 0.5725\n",
      "536/536 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.3172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f179b5d7780>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(turkishData,31 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Langugaes failed, because there are so categories that has only 1 article, which leaded into a problem because the training dataset and the validation dataset has different number of categories so this function is used to remove this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove1Row(inputD):\n",
    "    mydataset = inputD\n",
    "    value_counts = mydataset['Label'].value_counts()\n",
    "\n",
    "    # Select the values where the count is less than 3 (or 5 if you like)\n",
    "    to_remove = value_counts[value_counts < 2].index\n",
    "\n",
    "    # Keep rows where the city column is not in to_remove\n",
    "    mydataset = mydataset[~mydataset.Label.isin(to_remove)]\n",
    "    return mydataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0     178\n",
       "1       6\n",
       "2      48\n",
       "4      24\n",
       "6      97\n",
       "7      99\n",
       "9      99\n",
       "11    100\n",
       "12    198\n",
       "13    100\n",
       "14     92\n",
       "15    100\n",
       "16     86\n",
       "17      2\n",
       "18     99\n",
       "19    100\n",
       "21     57\n",
       "22    100\n",
       "23      2\n",
       "24    100\n",
       "25     10\n",
       "26     98\n",
       "27    100\n",
       "28    100\n",
       "29    100\n",
       "30    100\n",
       "31    100\n",
       "32    100\n",
       "33     96\n",
       "34     76\n",
       "35     72\n",
       "36     86\n",
       "37     95\n",
       "38     96\n",
       "39     64\n",
       "40     94\n",
       "41    100\n",
       "42     99\n",
       "43    100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Remove1Row(portugueseData)\n",
    "portugueseData.groupby(['Label']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Language  Label                                               Text\n",
      "45254  portuguese      1  Michel Temer (Deputado Federal) - 1986 Michel ...\n",
      "45255  portuguese      1  Museu Nacional: a história do Brasil transform...\n",
      "45256  portuguese      1  Imagem daquiAs casas fecham as pálpebras das j...\n",
      "45257  portuguese      1  Quando a Propaganda Vence as Eleições Quando a...\n",
      "45258  portuguese      1  Todo domingo a zebra do Fantástico anunciava o...\n",
      "[ 263  105    7    2 4462    1   10    1   23   25   20 2268   47   30\n",
      "   61   63 4461    4  974 1119  210  198   18   48   13    5    4  522\n",
      " 3547   15    3 4619  302 1300    8  119  268   98  549    3  678    7\n",
      "  519    8 2185  698    3 3459   32 4021   15   50  125   34  232 1327\n",
      "   23    6 1237   24   20   45    2  148    1    5   11   54  436   59\n",
      " 1158   12  982    6 1031    1    2  711    2 2687 2628    3 3547    2\n",
      "    1   58  287 1045   16  210  198   69    5   39    4  421    7 4305\n",
      "    1  125]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_99 (Embedding)     (None, 100, 50)           3121600   \n",
      "_________________________________________________________________\n",
      "gru_101 (GRU)                (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 39)                10023     \n",
      "=================================================================\n",
      "Total params: 3,367,399\n",
      "Trainable params: 3,367,399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2529 samples, validate on 844 samples\n",
      "Epoch 1/10\n",
      "2529/2529 [==============================] - 23s 9ms/step - loss: 3.5487 - acc: 0.0735 - val_loss: 3.4348 - val_acc: 0.0758\n",
      "Epoch 2/10\n",
      "2529/2529 [==============================] - 16s 6ms/step - loss: 3.3228 - acc: 0.0902 - val_loss: 3.2868 - val_acc: 0.0900\n",
      "Epoch 3/10\n",
      "2529/2529 [==============================] - 15s 6ms/step - loss: 3.0901 - acc: 0.1119 - val_loss: 3.0876 - val_acc: 0.1623\n",
      "Epoch 4/10\n",
      "2529/2529 [==============================] - 15s 6ms/step - loss: 2.7151 - acc: 0.2266 - val_loss: 2.8972 - val_acc: 0.2251\n",
      "Epoch 5/10\n",
      "2529/2529 [==============================] - 15s 6ms/step - loss: 2.3151 - acc: 0.3369 - val_loss: 2.8698 - val_acc: 0.2761\n",
      "Epoch 6/10\n",
      "2529/2529 [==============================] - 16s 6ms/step - loss: 2.0427 - acc: 0.4183 - val_loss: 2.5756 - val_acc: 0.3140\n",
      "Epoch 7/10\n",
      "2529/2529 [==============================] - 15s 6ms/step - loss: 1.7320 - acc: 0.4812 - val_loss: 2.6911 - val_acc: 0.3081\n",
      "Epoch 8/10\n",
      "2529/2529 [==============================] - 16s 6ms/step - loss: 1.4791 - acc: 0.5595 - val_loss: 2.6692 - val_acc: 0.3282\n",
      "Epoch 9/10\n",
      "2529/2529 [==============================] - 15s 6ms/step - loss: 1.3169 - acc: 0.5967 - val_loss: 2.6219 - val_acc: 0.3318\n",
      "Epoch 10/10\n",
      "2529/2529 [==============================] - 15s 6ms/step - loss: 1.1258 - acc: 0.6386 - val_loss: 2.6296 - val_acc: 0.3495\n",
      "2529/2529 [==============================] - 3s 1ms/step\n",
      "Training Accuracy: 0.7090\n",
      "844/844 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.3495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f1782e8acf8>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfunc(portugueseData,39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Language  Label                                               Text\n",
      "42390  norwegian     12  Flint wins 61st Annual CANUSA Games Jason Naso...\n",
      "42391  norwegian     12  Jwalamukhi Movie Part 08/12 || Rajesh Hamal, V...\n",
      "42392  norwegian     12  Oda Vige Helle 27/08/2018«Hvem bråker så mye o...\n",
      "42393  norwegian     12  Asbjørn Slettemark Leave a commentEr den nye u...\n",
      "42394  norwegian     12  Let’s livin’ it upYeah, one time forever mineF...\n",
      "[   3 3123  816  948 2617   32    4 1877    2    4    3    9 2882  331\n",
      "    5 3813    6   13   38 3814   96  477   18  173 4868 1582 3406   19\n",
      " 2618   15    4   12  112  271  452    4   12   32  112    8 1020 2289\n",
      "    9 1582   25    1 3124    5    2   96    3 4312   10  915   11  244\n",
      "    5    1 3407   24 1767 3813    4 1505    6   13    5   12 1582 1766\n",
      "    1  268  269    3    1    6   12    1  444  481   17 1582   52  117\n",
      "  134   10  208  314   11 1673    1  194  583 3408   77  816 1067 1673\n",
      "   19 1582]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_106 (Embedding)    (None, 100, 50)           1621100   \n",
      "_________________________________________________________________\n",
      "gru_108 (GRU)                (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 22)                5654      \n",
      "=================================================================\n",
      "Total params: 1,862,530\n",
      "Trainable params: 1,862,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 511 samples, validate on 171 samples\n",
      "Epoch 1/10\n",
      "511/511 [==============================] - 11s 22ms/step - loss: 3.0101 - acc: 0.1898 - val_loss: 2.5421 - val_acc: 0.1696\n",
      "Epoch 2/10\n",
      "511/511 [==============================] - 3s 6ms/step - loss: 2.5293 - acc: 0.1585 - val_loss: 2.5256 - val_acc: 0.1696\n",
      "Epoch 3/10\n",
      "511/511 [==============================] - 3s 5ms/step - loss: 2.4810 - acc: 0.1585 - val_loss: 2.4850 - val_acc: 0.1696\n",
      "Epoch 4/10\n",
      "511/511 [==============================] - 3s 6ms/step - loss: 2.4589 - acc: 0.1566 - val_loss: 2.4902 - val_acc: 0.1696\n",
      "Epoch 5/10\n",
      "511/511 [==============================] - 3s 5ms/step - loss: 2.4192 - acc: 0.1663 - val_loss: 2.4595 - val_acc: 0.1696\n",
      "Epoch 6/10\n",
      "511/511 [==============================] - 3s 6ms/step - loss: 2.3969 - acc: 0.1507 - val_loss: 2.4610 - val_acc: 0.1637\n",
      "Epoch 7/10\n",
      "511/511 [==============================] - 3s 5ms/step - loss: 2.3845 - acc: 0.1546 - val_loss: 2.4088 - val_acc: 0.1637\n",
      "Epoch 8/10\n",
      "511/511 [==============================] - 3s 5ms/step - loss: 2.3149 - acc: 0.1566 - val_loss: 2.3534 - val_acc: 0.1871\n",
      "Epoch 9/10\n",
      "511/511 [==============================] - 3s 5ms/step - loss: 2.2295 - acc: 0.2016 - val_loss: 2.2875 - val_acc: 0.2573\n",
      "Epoch 10/10\n",
      "511/511 [==============================] - 3s 5ms/step - loss: 2.1038 - acc: 0.1977 - val_loss: 2.1942 - val_acc: 0.2164\n",
      "511/511 [==============================] - 1s 1ms/step\n",
      "Training Accuracy: 0.2094\n",
      "171/171 [==============================] - 0s 1ms/step\n",
      "Testing Accuracy:  0.2164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f1783022048>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norwegianData = Remove1Row(norwegianData)\n",
    "myfunc(norwegianData,22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "18553  finnish      1  Fuckparade. Ehkä määrittävin hetki tämän vuode...\n",
      "18554  finnish      1  Berliini. Miten hieno on lauantai, jonka saa a...\n",
      "18555  finnish      1  View this post on InstagramFuckparade Lisää ku...\n",
      "18557  finnish     12  Annihilator ja D.O.A. perustajajäsen Randy Ram...\n",
      "18558  finnish     12  Lasten Hautausmaa jää luovalle tauolle tulevan...\n",
      "[ 450 1611 1076  450 1475   13   20   71    1 4084  255   10  230    1\n",
      " 1612   29 3037 1248    2  113 1402 4085 3038  286    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_108 (Embedding)    (None, 100, 50)           3698500   \n",
      "_________________________________________________________________\n",
      "gru_110 (GRU)                (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 27)                6939      \n",
      "=================================================================\n",
      "Total params: 3,941,215\n",
      "Trainable params: 3,941,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1207 samples, validate on 403 samples\n",
      "Epoch 1/10\n",
      "1207/1207 [==============================] - 15s 12ms/step - loss: 3.1259 - acc: 0.1060 - val_loss: 2.9477 - val_acc: 0.1538\n",
      "Epoch 2/10\n",
      "1207/1207 [==============================] - 7s 6ms/step - loss: 2.9958 - acc: 0.1127 - val_loss: 2.9245 - val_acc: 0.1538\n",
      "Epoch 3/10\n",
      "1207/1207 [==============================] - 7s 6ms/step - loss: 2.9436 - acc: 0.1127 - val_loss: 2.8460 - val_acc: 0.1538\n",
      "Epoch 4/10\n",
      "1207/1207 [==============================] - 7s 6ms/step - loss: 2.8081 - acc: 0.1160 - val_loss: 2.7287 - val_acc: 0.1538\n",
      "Epoch 5/10\n",
      "1207/1207 [==============================] - 7s 6ms/step - loss: 2.6870 - acc: 0.1947 - val_loss: 2.6644 - val_acc: 0.2159\n",
      "Epoch 6/10\n",
      "1207/1207 [==============================] - 7s 6ms/step - loss: 2.5346 - acc: 0.1930 - val_loss: 2.5683 - val_acc: 0.2159\n",
      "Epoch 7/10\n",
      "1207/1207 [==============================] - 7s 6ms/step - loss: 2.4472 - acc: 0.2378 - val_loss: 2.4774 - val_acc: 0.2333\n",
      "Epoch 8/10\n",
      "1207/1207 [==============================] - 7s 6ms/step - loss: 2.2785 - acc: 0.2908 - val_loss: 2.4179 - val_acc: 0.2581\n",
      "Epoch 9/10\n",
      "1207/1207 [==============================] - 7s 6ms/step - loss: 2.0653 - acc: 0.3380 - val_loss: 2.2828 - val_acc: 0.2705\n",
      "Epoch 10/10\n",
      "1207/1207 [==============================] - 8s 6ms/step - loss: 1.8102 - acc: 0.4085 - val_loss: 2.1571 - val_acc: 0.2953\n",
      "1207/1207 [==============================] - 2s 1ms/step\n",
      "Training Accuracy: 0.4921\n",
      "403/403 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.2953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f1780944dd8>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finnishData = Remove1Row(finnishData)\n",
    "myfunc(finnishData,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "4519  albanian     12  Anton Marku Anton Marku u lind më 15 gusht 197...\n",
      "4520  albanian     12  Më kanë dalë mbi sipërfaqe Dhe shpirti buçet, ...\n",
      "4521  albanian     12  Sonata e Dritëhënës!Natë, pranverore. Dhomë e ...\n",
      "4522  albanian     12  Ted HUGHESKalendari poetik: Ted Hughes (1930-1...\n",
      "4523  albanian     12  të prek shpirtin e saj të brishtë, shpirtin e ...\n",
      "[ 453    5 1891  688   31   59 1411  137   10  137 2774    3 2775    1\n",
      " 3528    4  112    4   70   92   12 1740  195    2 1514   28  794   42\n",
      "   42  479   64    1  246   12    1  381    9   28 2060  705    4  665\n",
      "    5  795 2776 1411   12    5 4647  168  442    1  922   14  168   17\n",
      "   79  232 1251   20 1741   75  320  176   12  443    5  729    6  382\n",
      " 1892  155   96 1619  155 1893    3 3529    8  489 2061    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_119 (Embedding)    (None, 100, 50)           1653800   \n",
      "_________________________________________________________________\n",
      "gru_121 (GRU)                (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 1,891,375\n",
      "Trainable params: 1,891,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/10\n",
      "426/426 [==============================] - 10s 25ms/step - loss: 1.9023 - acc: 0.3146 - val_loss: 1.6769 - val_acc: 0.3986\n",
      "Epoch 2/10\n",
      "426/426 [==============================] - 2s 5ms/step - loss: 1.7040 - acc: 0.3357 - val_loss: 1.6094 - val_acc: 0.3986\n",
      "Epoch 3/10\n",
      "426/426 [==============================] - 2s 5ms/step - loss: 1.6725 - acc: 0.3357 - val_loss: 1.5879 - val_acc: 0.3986\n",
      "Epoch 4/10\n",
      "426/426 [==============================] - 2s 5ms/step - loss: 1.5620 - acc: 0.3357 - val_loss: 1.4760 - val_acc: 0.3986\n",
      "Epoch 5/10\n",
      "426/426 [==============================] - 2s 5ms/step - loss: 1.4408 - acc: 0.3357 - val_loss: 1.3469 - val_acc: 0.3986\n",
      "Epoch 6/10\n",
      "426/426 [==============================] - 2s 6ms/step - loss: 1.2473 - acc: 0.4437 - val_loss: 1.2269 - val_acc: 0.5105\n",
      "Epoch 7/10\n",
      "426/426 [==============================] - 2s 5ms/step - loss: 1.0587 - acc: 0.6197 - val_loss: 1.1294 - val_acc: 0.5175\n",
      "Epoch 8/10\n",
      "426/426 [==============================] - 2s 5ms/step - loss: 0.9322 - acc: 0.6338 - val_loss: 1.1363 - val_acc: 0.5944\n",
      "Epoch 9/10\n",
      "426/426 [==============================] - 2s 5ms/step - loss: 1.0734 - acc: 0.6432 - val_loss: 1.2356 - val_acc: 0.5524\n",
      "Epoch 10/10\n",
      "426/426 [==============================] - 2s 6ms/step - loss: 0.8838 - acc: 0.6596 - val_loss: 1.3890 - val_acc: 0.6154\n",
      "426/426 [==============================] - 1s 1ms/step\n",
      "Training Accuracy: 0.6620\n",
      "143/143 [==============================] - 0s 1ms/step\n",
      "Testing Accuracy:  0.6154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f1769568cf8>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albanianData = Remove1Row(albanianData)\n",
    "myfunc(albanianData,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Language  Label                                               Text\n",
      "17842  estonian     12  JagaUus kooliaasta on kohe algamas ja seoses s...\n",
      "17843  estonian     12  Breakfast With The Beatles – August 19, 2018 M...\n",
      "17844  estonian     12  JagaAlles eelmise aasta lõpus esitletud Micros...\n",
      "17845  estonian     12  JagaTelerite heli võib küll olla üsna hea, kui...\n",
      "17846  estonian     12  JagaOn olemas erinevaid mobiilipakette, samuti...\n",
      "[  15  443 1111    7  626   29   38   18  599  844  219   56  443    1\n",
      "   95   32   18 3039    1   56 1023  171  191 1109 2217   47   16  599\n",
      "  288   15  443 1111    2  626  219  418  884   18   22   56  843   15\n",
      "  443    2 4839 1869   18   18   56    1   15 4061   95   47   36   56\n",
      "  844  154  101   19   18  599   56  443    2  625  740   18   16 3039\n",
      "    1  171   56 1023  561  599  843   15  443 1111  174  983  599   15\n",
      "  914    1  600 4063 3518  208 1865  134  524  914   50   56    2 1866\n",
      "  599  323]\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_121 (Embedding)    (None, 100, 50)           1607400   \n",
      "_________________________________________________________________\n",
      "gru_123 (GRU)                (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 1,847,288\n",
      "Trainable params: 1,847,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 530 samples, validate on 177 samples\n",
      "Epoch 1/10\n",
      "530/530 [==============================] - 12s 23ms/step - loss: 2.6692 - acc: 0.1509 - val_loss: 2.4020 - val_acc: 0.1412\n",
      "Epoch 2/10\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 2.3710 - acc: 0.1358 - val_loss: 2.3870 - val_acc: 0.1412\n",
      "Epoch 3/10\n",
      "530/530 [==============================] - 3s 6ms/step - loss: 2.3432 - acc: 0.1358 - val_loss: 2.3352 - val_acc: 0.1412\n",
      "Epoch 4/10\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 2.3174 - acc: 0.1585 - val_loss: 2.3219 - val_acc: 0.2147\n",
      "Epoch 5/10\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 2.2770 - acc: 0.2132 - val_loss: 2.2408 - val_acc: 0.2542\n",
      "Epoch 6/10\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 2.1647 - acc: 0.2000 - val_loss: 2.1130 - val_acc: 0.2147\n",
      "Epoch 7/10\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 2.0299 - acc: 0.2189 - val_loss: 2.1061 - val_acc: 0.2034\n",
      "Epoch 8/10\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 2.5119 - acc: 0.1887 - val_loss: 3.1895 - val_acc: 0.0621\n",
      "Epoch 9/10\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 2.3622 - acc: 0.3283 - val_loss: 2.4136 - val_acc: 0.2429\n",
      "Epoch 10/10\n",
      "530/530 [==============================] - 3s 5ms/step - loss: 2.2876 - acc: 0.3604 - val_loss: 2.2970 - val_acc: 0.2429\n",
      "530/530 [==============================] - 1s 1ms/step\n",
      "Training Accuracy: 0.3717\n",
      "177/177 [==============================] - 0s 1ms/step\n",
      "Testing Accuracy:  0.2429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f176808ef60>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estonianData = Remove1Row(estonianData)\n",
    "myfunc(estonianData,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language  Label                                               Text\n",
      "59630  swedish      1  18 augusti, 2018Moderaternas partiledare Ulf K...\n",
      "59631  swedish      1  22 augusti, 2018Ylva Johansson (S), Ali Esbati...\n",
      "59632  swedish      1  Jag förstår Vi sparar data i cookies , genom a...\n",
      "59633  swedish      1  Politik Het valdebatt om lasGrus i maskineriet...\n",
      "59634  swedish      1  5 september, 2018Christoffer Röstlund Jonsson ...\n",
      "[4932 2437  136   11   25    1    3  371  414 2073 4329   13   39   30\n",
      "   42    2   74 3832   14  195  168   81 1309 2945   12   37  176 4635\n",
      "    1 2074 2438    5 4932   11   25    1 3833 4933 2203    5    8   50\n",
      " 1689  242  160   25  160   68   11   12   42 4080  350   18 1370    3\n",
      "  541   10 1309   39 1635 1259  439   52  118 2722    3 3834    1 2075\n",
      " 1214    6    4  212  935 1106 2438    1   69 4329   13 4934  732    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_123 (Embedding)    (None, 100, 50)           2862300   \n",
      "_________________________________________________________________\n",
      "gru_125 (GRU)                (None, 256)               235776    \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 32)                8224      \n",
      "=================================================================\n",
      "Total params: 3,106,300\n",
      "Trainable params: 3,106,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1748 samples, validate on 583 samples\n",
      "Epoch 1/10\n",
      "1748/1748 [==============================] - 19s 11ms/step - loss: 3.3104 - acc: 0.0755 - val_loss: 3.1929 - val_acc: 0.0961\n",
      "Epoch 2/10\n",
      "1748/1748 [==============================] - 10s 6ms/step - loss: 3.1280 - acc: 0.1064 - val_loss: 3.0860 - val_acc: 0.0978\n",
      "Epoch 3/10\n",
      "1748/1748 [==============================] - 10s 6ms/step - loss: 2.9487 - acc: 0.1510 - val_loss: 2.8919 - val_acc: 0.1355\n",
      "Epoch 4/10\n",
      "1748/1748 [==============================] - 10s 6ms/step - loss: 2.6965 - acc: 0.2031 - val_loss: 2.7118 - val_acc: 0.2539\n",
      "Epoch 5/10\n",
      "1748/1748 [==============================] - 10s 6ms/step - loss: 2.3743 - acc: 0.3021 - val_loss: 2.5759 - val_acc: 0.2796\n",
      "Epoch 6/10\n",
      "1748/1748 [==============================] - 10s 6ms/step - loss: 2.1030 - acc: 0.3947 - val_loss: 2.5174 - val_acc: 0.2967\n",
      "Epoch 7/10\n",
      "1748/1748 [==============================] - 10s 6ms/step - loss: 1.8532 - acc: 0.4594 - val_loss: 2.4852 - val_acc: 0.3173\n",
      "Epoch 8/10\n",
      "1748/1748 [==============================] - 10s 6ms/step - loss: 1.6769 - acc: 0.5086 - val_loss: 2.5193 - val_acc: 0.3173\n",
      "Epoch 9/10\n",
      "1748/1748 [==============================] - 10s 6ms/step - loss: 1.4946 - acc: 0.5543 - val_loss: 2.4574 - val_acc: 0.3242\n",
      "Epoch 10/10\n",
      "1748/1748 [==============================] - 10s 6ms/step - loss: 1.3337 - acc: 0.5915 - val_loss: 2.5344 - val_acc: 0.3465\n",
      "1748/1748 [==============================] - 2s 1ms/step\n",
      "Training Accuracy: 0.6379\n",
      "583/583 [==============================] - 1s 1ms/step\n",
      "Testing Accuracy:  0.3465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f1767494c18>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swedishData = Remove1Row(swedishData)\n",
    "myfunc(swedishData,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
